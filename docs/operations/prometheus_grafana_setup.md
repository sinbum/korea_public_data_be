# ğŸ“Š Prometheus/Grafana ëª¨ë‹ˆí„°ë§ ì„¤ì •

> Korea Public Data Backendì˜ ì¢…í•©ì ì¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
- [ëª¨ë‹ˆí„°ë§ ê°œìš”](#ëª¨ë‹ˆí„°ë§-ê°œìš”)
- [Prometheus ì„¤ì •](#prometheus-ì„¤ì •)
- [Grafana ì„¤ì •](#grafana-ì„¤ì •)
- [ë©”íŠ¸ë¦­ ì •ì˜](#ë©”íŠ¸ë¦­-ì •ì˜)
- [ëŒ€ì‹œë³´ë“œ êµ¬ì„±](#ëŒ€ì‹œë³´ë“œ-êµ¬ì„±)
- [ì•Œë¦¼ ì„¤ì •](#ì•Œë¦¼-ì„¤ì •)
- [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
- [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

## ğŸ¯ ëª¨ë‹ˆí„°ë§ ê°œìš”

### ëª¨ë‹ˆí„°ë§ ëª©í‘œ
1. **ì‹œìŠ¤í…œ ê°€ìš©ì„±**: ì„œë¹„ìŠ¤ ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
2. **ì„±ëŠ¥ ì¶”ì **: API ì‘ë‹µ ì‹œê°„, ì²˜ë¦¬ëŸ‰, ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
3. **ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­**: ì‚¬ìš©ì í™œë™, ì½˜í…ì¸  ì„±ê³¼, ë¹„ì¦ˆë‹ˆìŠ¤ KPI
4. **ì˜¤ë¥˜ íƒì§€**: ì˜ˆì™¸, ì¥ì• , ì„±ëŠ¥ ì €í•˜ ì¡°ê¸° ê°ì§€
5. **ìš©ëŸ‰ ê³„íš**: ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íŒ¨í„´ ë¶„ì„ ë° í™•ì¥ ê³„íš

### ì•„í‚¤í…ì²˜ êµ¬ì¡°
```mermaid
graph TB
    A[FastAPI Application] --> B[Prometheus Metrics]
    C[MongoDB] --> D[MongoDB Exporter]
    E[Redis] --> F[Redis Exporter]
    G[Node/Container] --> H[Node Exporter]
    
    B --> I[Prometheus Server]
    D --> I
    F --> I
    H --> I
    
    I --> J[Grafana]
    I --> K[AlertManager]
    
    J --> L[Dashboards]
    K --> M[Notifications]
    
    style A fill:#e1f5fe
    style I fill:#f3e5f5
    style J fill:#e8f5e8
    style K fill:#fff3e0
```

### êµ¬ì„± ìš”ì†Œ
- **Prometheus**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
- **Grafana**: ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ
- **AlertManager**: ì•Œë¦¼ ê´€ë¦¬
- **Exporters**: ì™¸ë¶€ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- **Application Metrics**: ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë©”íŠ¸ë¦­

## ğŸ”§ Prometheus ì„¤ì •

### Docker Compose ì„¤ì •
```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    restart: unless-stopped
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:10.0.0
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123!
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - prometheus

  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager:/etc/alertmanager
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    restart: unless-stopped
    networks:
      - monitoring

  # ì™¸ë¶€ ì‹œìŠ¤í…œ Exporters
  mongodb_exporter:
    image: percona/mongodb_exporter:0.39
    container_name: mongodb_exporter
    ports:
      - "9216:9216"
    environment:
      - MONGODB_URI=mongodb://localhost:27017
    command:
      - '--mongodb.uri=mongodb://mongodb:27017'
      - '--collect-all'
    restart: unless-stopped
    networks:
      - monitoring
      - korea_network
    depends_on:
      - mongodb

  redis_exporter:
    image: oliver006/redis_exporter:v1.52.0
    container_name: redis_exporter
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis:6379
    restart: unless-stopped
    networks:
      - monitoring
      - korea_network
    depends_on:
      - redis

  node_exporter:
    image: prom/node-exporter:v1.6.0
    container_name: node_exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:

networks:
  monitoring:
    driver: bridge
  korea_network:
    external: true
```

### Prometheus ì„¤ì • íŒŒì¼
```yaml
# monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'korea-public-data'
    environment: 'production'

rule_files:
  - "alert_rules.yml"
  - "recording_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
  - job_name: 'fastapi-app'
    static_configs:
      - targets: ['korea-backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
    scrape_timeout: 5s

  # MongoDB
  - job_name: 'mongodb'
    static_configs:
      - targets: ['mongodb_exporter:9216']
    scrape_interval: 30s

  # Redis
  - job_name: 'redis'
    static_configs:
      - targets: ['redis_exporter:9121']
    scrape_interval: 30s

  # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
  - job_name: 'node'
    static_configs:
      - targets: ['node_exporter:9100']
    scrape_interval: 30s

  # Prometheus ìì²´ ëª¨ë‹ˆí„°ë§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Grafana
  - job_name: 'grafana'
    static_configs:
      - targets: ['grafana:3000']
    metrics_path: '/metrics'

  # ì¶”ê°€ ì„œë¹„ìŠ¤ (í•„ìš”ì‹œ í™œì„±í™”)
  # - job_name: 'elasticsearch'
  #   static_configs:
  #     - targets: ['elasticsearch:9200']
```

### ì•Œë¦¼ ê·œì¹™ ì„¤ì •
```yaml
# monitoring/prometheus/alert_rules.yml
groups:
  - name: korea_public_data_alerts
    rules:
      # ì¸ìŠ¤í„´ìŠ¤ ë‹¤ìš´
      - alert: InstanceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Instance {{ $labels.instance }} is down"
          description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute."

      # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% for more than 5 minutes. Current value: {{ $value }}%"

      # ë†’ì€ CPU ì‚¬ìš©ë¥ 
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% for more than 5 minutes. Current value: {{ $value }}%"

      # ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ë†’ìŒ
      - alert: HighDiskUsage
        expr: (1 - node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"}) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High disk usage on {{ $labels.instance }}"
          description: "Disk usage on {{ $labels.mountpoint }} is above 85%. Current value: {{ $value }}%"

      # API ì‘ë‹µ ì‹œê°„ ë†’ìŒ
      - alert: HighAPIResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "High API response time"
          description: "95th percentile response time is above 1 second for more than 3 minutes. Current value: {{ $value }}s"

      # API ì—ëŸ¬ìœ¨ ë†’ìŒ
      - alert: HighAPIErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 3m
        labels:
          severity: critical
        annotations:
          summary: "High API error rate"
          description: "API error rate is above 5% for more than 3 minutes. Current value: {{ $value }}%"

      # MongoDB ì—°ê²° ì‹¤íŒ¨
      - alert: MongoDBDown
        expr: mongodb_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "MongoDB is down"
          description: "MongoDB instance is not responding for more than 1 minute."

      # Redis ì—°ê²° ì‹¤íŒ¨
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis is down"
          description: "Redis instance is not responding for more than 1 minute."

      # ì‚¬ìš©ì í™œë™ ê¸‰ê°
      - alert: UserActivityDrop
        expr: (
          rate(user_activity_total[10m]) < 
          rate(user_activity_total[1h] offset 24h) * 0.5
        )
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Significant drop in user activity"
          description: "User activity has dropped by more than 50% compared to the same time yesterday."

      # ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ìš”ì²­ëŸ‰
      - alert: UnusuallyHighRequestVolume
        expr: rate(http_requests_total[5m]) > rate(http_requests_total[1h] offset 24h) * 3
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Unusually high request volume"
          description: "Request volume is more than 3x higher than the same time yesterday."
```

### ë ˆì½”ë”© ê·œì¹™ ì„¤ì •
```yaml
# monitoring/prometheus/recording_rules.yml
groups:
  - name: korea_public_data_recording_rules
    interval: 30s
    rules:
      # API ë©”íŠ¸ë¦­ ì§‘ê³„
      - record: api:request_rate:5m
        expr: rate(http_requests_total[5m])

      - record: api:request_rate:1h
        expr: rate(http_requests_total[1h])

      - record: api:error_rate:5m
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])

      - record: api:response_time:p95:5m
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

      - record: api:response_time:p99:5m
        expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

      # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì§‘ê³„
      - record: system:cpu_usage:5m
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

      - record: system:memory_usage:current
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

      - record: system:disk_usage:current
        expr: (1 - node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"}) * 100

      # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
      - record: app:active_users:5m
        expr: increase(active_users_total[5m])

      - record: app:content_views:1h
        expr: increase(content_views_total[1h])

      - record: app:api_calls_by_endpoint:5m
        expr: sum by(endpoint) (rate(http_requests_total[5m]))
```

## ğŸ“Š Grafana ì„¤ì •

### ë°ì´í„°ì†ŒìŠ¤ ì„¤ì •
```yaml
# monitoring/grafana/provisioning/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
    jsonData:
      httpMethod: POST
      exemplarTraceIdDestinations:
        - name: traceID
          datasourceUid: jaeger
          url: http://jaeger:16686/trace/${__value.raw}

  - name: AlertManager
    type: alertmanager
    access: proxy
    url: http://alertmanager:9093
    editable: true
```

### ëŒ€ì‹œë³´ë“œ í”„ë¡œë¹„ì €ë‹
```yaml
# monitoring/grafana/provisioning/dashboards/default.yml
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /var/lib/grafana/dashboards
```

### ì‹œìŠ¤í…œ ê°œìš” ëŒ€ì‹œë³´ë“œ
```json
{
  "dashboard": {
    "id": null,
    "title": "Korea Public Data - System Overview",
    "tags": ["korea", "system", "overview"],
    "timezone": "Asia/Seoul",
    "panels": [
      {
        "id": 1,
        "title": "System Health Status",
        "type": "stat",
        "targets": [
          {
            "expr": "up",
            "legendFormat": "{{instance}}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "green", "value": 1}
              ]
            },
            "mappings": [
              {"options": {"0": {"text": "DOWN"}}, "type": "value"},
              {"options": {"1": {"text": "UP"}}, "type": "value"}
            ]
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "API Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[5m]))",
            "legendFormat": "Total Requests/sec"
          },
          {
            "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m]))",
            "legendFormat": "Error Requests/sec"
          }
        ],
        "yAxes": [
          {
            "label": "Requests/sec",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "Response Time (95th percentile)",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "Seconds",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 0}
      },
      {
        "id": 4,
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg by(instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "{{instance}}"
          }
        ],
        "yAxes": [
          {
            "label": "Percent",
            "min": 0,
            "max": 100
          }
        ],
        "gridPos": {"h": 8, "w": 8, "x": 0, "y": 8}
      },
      {
        "id": 5,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
            "legendFormat": "{{instance}}"
          }
        ],
        "yAxes": [
          {
            "label": "Percent",
            "min": 0,
            "max": 100
          }
        ],
        "gridPos": {"h": 8, "w": 8, "x": 8, "y": 8}
      },
      {
        "id": 6,
        "title": "Disk Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "(1 - node_filesystem_avail_bytes{fstype!=\"tmpfs\"} / node_filesystem_size_bytes{fstype!=\"tmpfs\"}) * 100",
            "legendFormat": "{{instance}}:{{mountpoint}}"
          }
        ],
        "yAxes": [
          {
            "label": "Percent",
            "min": 0,
            "max": 100
          }
        ],
        "gridPos": {"h": 8, "w": 8, "x": 16, "y": 8}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

### API ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ
```json
{
  "dashboard": {
    "id": null,
    "title": "Korea Public Data - API Performance",
    "tags": ["korea", "api", "performance"],
    "panels": [
      {
        "id": 1,
        "title": "Requests by Endpoint",
        "type": "graph",
        "targets": [
          {
            "expr": "sum by(endpoint) (rate(http_requests_total[5m]))",
            "legendFormat": "{{endpoint}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Response Time by Endpoint",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum by(endpoint, le) (rate(http_request_duration_seconds_bucket[5m])))",
            "legendFormat": "{{endpoint}} (95th)"
          },
          {
            "expr": "histogram_quantile(0.50, sum by(endpoint, le) (rate(http_request_duration_seconds_bucket[5m])))",
            "legendFormat": "{{endpoint}} (50th)"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "Error Rate by Endpoint",
        "type": "graph",
        "targets": [
          {
            "expr": "sum by(endpoint) (rate(http_requests_total{status=~\"5..\"}[5m])) / sum by(endpoint) (rate(http_requests_total[5m])) * 100",
            "legendFormat": "{{endpoint}}"
          }
        ],
        "yAxes": [
          {
            "label": "Error Rate (%)",
            "min": 0
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
      },
      {
        "id": 4,
        "title": "Top Slowest Endpoints",
        "type": "table",
        "targets": [
          {
            "expr": "topk(10, histogram_quantile(0.95, sum by(endpoint, le) (rate(http_request_duration_seconds_bucket[5m]))))",
            "format": "table",
            "instant": true
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16}
      },
      {
        "id": 5,
        "title": "Request Volume Trend",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(increase(http_requests_total[1h]))",
            "legendFormat": "Requests per hour"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16}
      }
    ],
    "time": {
      "from": "now-6h",
      "to": "now"
    },
    "refresh": "1m"
  }
}
```

### ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ
```json
{
  "dashboard": {
    "id": null,
    "title": "Korea Public Data - Business Metrics",
    "tags": ["korea", "business", "kpi"],
    "panels": [
      {
        "id": 1,
        "title": "Active Users",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(increase(active_users_total[5m]))",
            "legendFormat": "5ë¶„ê°„ í™œì„± ì‚¬ìš©ì"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "palette-classic"
            },
            "unit": "short"
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Content Views",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(increase(content_views_total[1h]))",
            "legendFormat": "1ì‹œê°„ ì½˜í…ì¸  ì¡°íšŒ"
          }
        ],
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "API Calls Distribution",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum by(endpoint) (increase(http_requests_total[1h]))",
            "legendFormat": "{{endpoint}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 4,
        "title": "User Activity Over Time",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(user_actions_total[5m])) by (action_type)",
            "legendFormat": "{{action_type}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4}
      },
      {
        "id": 5,
        "title": "Popular Content Categories",
        "type": "bargauge",
        "targets": [
          {
            "expr": "topk(10, sum by(category) (increase(content_views_total[24h])))",
            "legendFormat": "{{category}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 12}
      },
      {
        "id": 6,
        "title": "Search Queries Trend",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(increase(search_queries_total[1h]))",
            "legendFormat": "Search Queries/hour"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 12}
      }
    ],
    "time": {
      "from": "now-24h",
      "to": "now"
    },
    "refresh": "5m"
  }
}
```

## ğŸ“¢ AlertManager ì„¤ì •

### AlertManager ì„¤ì • íŒŒì¼
```yaml
# monitoring/alertmanager/alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@korea-public-data.com'
  smtp_auth_username: 'alerts@korea-public-data.com'
  smtp_auth_password: 'your-smtp-password'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      repeat_interval: 30m
    
    - match:
        severity: warning
      receiver: 'warning-alerts'
      repeat_interval: 2h

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://alertmanager-webhook:5000/webhook'
        send_resolved: true

  - name: 'critical-alerts'
    email_configs:
      - to: 'dev-team@korea-public-data.com'
        subject: '[CRITICAL] Korea Public Data Alert'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          {{ end }}
    
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#critical-alerts'
        title: 'Critical Alert - Korea Public Data'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}

  - name: 'warning-alerts'
    email_configs:
      - to: 'monitoring@korea-public-data.com'
        subject: '[WARNING] Korea Public Data Alert'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
```

## ğŸ“Š ë©”íŠ¸ë¦­ ì •ì˜

### ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
```python
# app/monitoring/metrics.py

from prometheus_client import Counter, Histogram, Gauge, Info, Enum
from prometheus_client import start_http_server, CONTENT_TYPE_LATEST, REGISTRY
from prometheus_client.openmetrics.exposition import CONTENT_TYPE_LATEST as OPENMETRICS_CONTENT_TYPE
import time
from functools import wraps

# HTTP ìš”ì²­ ë©”íŠ¸ë¦­
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
)

# ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
active_users_total = Counter(
    'active_users_total',
    'Total active users',
    ['time_window']
)

content_views_total = Counter(
    'content_views_total',
    'Total content views',
    ['content_type', 'category']
)

search_queries_total = Counter(
    'search_queries_total',
    'Total search queries',
    ['search_type', 'result_count_range']
)

user_actions_total = Counter(
    'user_actions_total',
    'Total user actions',
    ['action_type', 'target_type']
)

# ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
database_connections = Gauge(
    'database_connections_active',
    'Active database connections',
    ['database_type']
)

cache_hit_rate = Gauge(
    'cache_hit_rate',
    'Cache hit rate',
    ['cache_type']
)

queue_size = Gauge(
    'queue_size',
    'Queue size',
    ['queue_name']
)

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë³´
app_info = Info(
    'app_info',
    'Application information'
)

# ì„œë¹„ìŠ¤ ìƒíƒœ
service_status = Enum(
    'service_status',
    'Service status',
    ['service_name'],
    states=['healthy', 'degraded', 'unhealthy']
)

def monitor_endpoint(endpoint_name: str):
    """ì—”ë“œí¬ì¸íŠ¸ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(request, *args, **kwargs):
            method = request.method
            start_time = time.time()
            status = "200"
            
            try:
                response = await func(request, *args, **kwargs)
                if hasattr(response, 'status_code'):
                    status = str(response.status_code)
                return response
            except Exception as e:
                status = "500"
                raise
            finally:
                duration = time.time() - start_time
                
                http_requests_total.labels(
                    method=method,
                    endpoint=endpoint_name,
                    status=status
                ).inc()
                
                http_request_duration_seconds.labels(
                    method=method,
                    endpoint=endpoint_name
                ).observe(duration)
        
        return wrapper
    return decorator

class MetricsCollector:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.start_time = time.time()
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë³´ ì„¤ì •
        app_info.info({
            'version': '1.0.0',
            'build_date': '2025-08-14',
            'environment': 'production'
        })
    
    def record_user_action(self, action_type: str, target_type: str):
        """ì‚¬ìš©ì ì•¡ì…˜ ê¸°ë¡"""
        user_actions_total.labels(
            action_type=action_type,
            target_type=target_type
        ).inc()
    
    def record_content_view(self, content_type: str, category: str):
        """ì½˜í…ì¸  ì¡°íšŒ ê¸°ë¡"""
        content_views_total.labels(
            content_type=content_type,
            category=category
        ).inc()
    
    def record_search_query(self, search_type: str, result_count: int):
        """ê²€ìƒ‰ ì¿¼ë¦¬ ê¸°ë¡"""
        # ê²°ê³¼ ìˆ˜ë¥¼ ë²”ìœ„ë¡œ ë¶„ë¥˜
        if result_count == 0:
            result_range = "0"
        elif result_count <= 10:
            result_range = "1-10"
        elif result_count <= 50:
            result_range = "11-50"
        elif result_count <= 100:
            result_range = "51-100"
        else:
            result_range = "100+"
        
        search_queries_total.labels(
            search_type=search_type,
            result_count_range=result_range
        ).inc()
    
    def update_database_connections(self, database_type: str, count: int):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìˆ˜ ì—…ë°ì´íŠ¸"""
        database_connections.labels(database_type=database_type).set(count)
    
    def update_cache_hit_rate(self, cache_type: str, hit_rate: float):
        """ìºì‹œ íˆíŠ¸ìœ¨ ì—…ë°ì´íŠ¸"""
        cache_hit_rate.labels(cache_type=cache_type).set(hit_rate)
    
    def update_queue_size(self, queue_name: str, size: int):
        """í í¬ê¸° ì—…ë°ì´íŠ¸"""
        queue_size.labels(queue_name=queue_name).set(size)
    
    def update_service_status(self, service_name: str, status: str):
        """ì„œë¹„ìŠ¤ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        service_status.labels(service_name=service_name).state(status)

# ì „ì—­ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¸ìŠ¤í„´ìŠ¤
metrics_collector = MetricsCollector()
```

### ë¯¸ë“¤ì›¨ì–´ í†µí•©
```python
# app/middleware/metrics_middleware.py

import time
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
from ..monitoring.metrics import http_requests_total, http_request_duration_seconds

class MetricsMiddleware(BaseHTTPMiddleware):
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¯¸ë“¤ì›¨ì–´"""
    
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        
        # ìš”ì²­ ì •ë³´ ì¶”ì¶œ
        method = request.method
        path = request.url.path
        
        # ê²½ë¡œ ì •ê·œí™” (ë§¤ê°œë³€ìˆ˜ ì œê±°)
        normalized_path = self.normalize_path(path)
        
        response = await call_next(request)
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        duration = time.time() - start_time
        
        # ë©”íŠ¸ë¦­ ê¸°ë¡
        http_requests_total.labels(
            method=method,
            endpoint=normalized_path,
            status=str(response.status_code)
        ).inc()
        
        http_request_duration_seconds.labels(
            method=method,
            endpoint=normalized_path
        ).observe(duration)
        
        return response
    
    def normalize_path(self, path: str) -> str:
        """ê²½ë¡œ ì •ê·œí™” (ID ë“± ë™ì  ë¶€ë¶„ ì œê±°)"""
        # API ê²½ë¡œì—ì„œ ë™ì  ë¶€ë¶„ì„ ì¼ë°˜í™”
        import re
        
        # UUID íŒ¨í„´ ì œê±°
        path = re.sub(r'/[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}', '/{id}', path)
        
        # ìˆ«ì ID íŒ¨í„´ ì œê±°
        path = re.sub(r'/\d+', '/{id}', path)
        
        # ObjectId íŒ¨í„´ ì œê±°
        path = re.sub(r'/[0-9a-f]{24}', '/{id}', path)
        
        return path
```

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### Prometheus ìµœì í™”
```yaml
# monitoring/prometheus/prometheus.yml (ìµœì í™” ì„¤ì •)
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  
  # ì™¸ë¶€ ë ˆì´ë¸”ë¡œ í´ëŸ¬ìŠ¤í„° ì‹ë³„
  external_labels:
    cluster: 'korea-public-data'
    replica: '1'

# ìŠ¤í† ë¦¬ì§€ ìµœì í™”
storage:
  tsdb:
    retention.time: 30d
    retention.size: 10GB
    wal-compression: true
    
# ì¿¼ë¦¬ ìµœì í™”
query:
  max-concurrency: 20
  timeout: 2m
  max-samples: 50000000

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìµœì í™”
scrape_configs:
  - job_name: 'fastapi-app'
    scrape_interval: 10s
    scrape_timeout: 5s
    metrics_path: '/metrics'
    honor_labels: true
    static_configs:
      - targets: ['korea-backend:8000']
    
    # ë©”íŠ¸ë¦­ í•„í„°ë§
    metric_relabel_configs:
      # ë¶ˆí•„ìš”í•œ ë©”íŠ¸ë¦­ ì œê±°
      - source_labels: [__name__]
        regex: 'go_.*'
        action: drop
      
      # ë†’ì€ ì¹´ë””ë„ë¦¬í‹° ë©”íŠ¸ë¦­ ìƒ˜í”Œë§
      - source_labels: [__name__]
        regex: 'http_requests_total'
        target_label: __tmp_sample
        replacement: '1'
      
      # ë ˆì´ë¸” ì •ê·œí™”
      - source_labels: [endpoint]
        regex: '/api/v1/.*'
        target_label: api_version
        replacement: 'v1'

# ì›ê²© ì €ì¥ì†Œ ì„¤ì • (ì„ íƒì‚¬í•­)
remote_write:
  - url: "https://prometheus-remote-write-endpoint.com/api/v1/write"
    queue_config:
      capacity: 10000
      max_shards: 1000
      min_shards: 1
      max_samples_per_send: 2000
      batch_send_deadline: 5s
```

### Grafana ìµœì í™”
```yaml
# monitoring/grafana/grafana.ini
[server]
protocol = http
http_port = 3000
enable_gzip = true

[database]
type = postgres
host = postgres:5432
name = grafana
user = grafana
password = grafana_password

[session]
provider = postgres
provider_config = user=grafana password=grafana_password host=postgres port=5432 dbname=grafana sslmode=disable

[analytics]
reporting_enabled = false
check_for_updates = false

[security]
admin_user = admin
admin_password = secure_admin_password
secret_key = your_secret_key

[users]
allow_sign_up = false
auto_assign_org = true
auto_assign_org_role = Viewer

[auth.anonymous]
enabled = false

[log]
mode = console file
level = warn

[metrics]
enabled = true
interval_seconds = 10

[alerting]
enabled = true
execute_alerts = true

[unified_alerting]
enabled = true
```

## ğŸ”§ ë°°í¬ ë° ìš´ì˜

### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# scripts/deploy_monitoring.sh

set -e

echo "ğŸš€ Deploying monitoring stack..."

# ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p monitoring/{prometheus,grafana,alertmanager}
mkdir -p monitoring/grafana/{provisioning/{datasources,dashboards},dashboards}

# ì„¤ì • íŒŒì¼ ê¶Œí•œ ì„¤ì •
chmod 644 monitoring/prometheus/*.yml
chmod 644 monitoring/grafana/provisioning/**/*.yml
chmod 644 monitoring/alertmanager/*.yml

# Docker ë„¤íŠ¸ì›Œí¬ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
docker network create monitoring 2>/dev/null || true

# ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘
echo "ğŸ“Š Starting Prometheus..."
docker-compose -f docker-compose.monitoring.yml up -d prometheus

# Prometheus ì‹œì‘ ëŒ€ê¸°
echo "â³ Waiting for Prometheus to start..."
sleep 10

# AlertManager ì‹œì‘
echo "ğŸ”” Starting AlertManager..."
docker-compose -f docker-compose.monitoring.yml up -d alertmanager

# Grafana ì‹œì‘
echo "ğŸ“ˆ Starting Grafana..."
docker-compose -f docker-compose.monitoring.yml up -d grafana

# Exporters ì‹œì‘
echo "ğŸ“¡ Starting exporters..."
docker-compose -f docker-compose.monitoring.yml up -d mongodb_exporter redis_exporter node_exporter

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo "ğŸ” Checking service status..."
sleep 20

# ì„œë¹„ìŠ¤ URL ì¶œë ¥
echo "âœ… Monitoring stack deployed successfully!"
echo ""
echo "ğŸ“Š Service URLs:"
echo "  Prometheus: http://localhost:9090"
echo "  Grafana: http://localhost:3000 (admin/admin123!)"
echo "  AlertManager: http://localhost:9093"
echo ""
echo "ğŸ“ˆ Default Dashboards:"
echo "  System Overview: http://localhost:3000/d/system-overview"
echo "  API Performance: http://localhost:3000/d/api-performance"
echo "  Business Metrics: http://localhost:3000/d/business-metrics"
```

### í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# scripts/check_monitoring_health.sh

echo "ğŸ” Checking monitoring stack health..."

# Prometheus í—¬ìŠ¤ì²´í¬
echo "ğŸ“Š Checking Prometheus..."
if curl -s http://localhost:9090/-/healthy > /dev/null; then
    echo "  âœ… Prometheus is healthy"
else
    echo "  âŒ Prometheus is not responding"
fi

# Grafana í—¬ìŠ¤ì²´í¬
echo "ğŸ“ˆ Checking Grafana..."
if curl -s http://localhost:3000/api/health | grep -q "ok"; then
    echo "  âœ… Grafana is healthy"
else
    echo "  âŒ Grafana is not responding"
fi

# AlertManager í—¬ìŠ¤ì²´í¬
echo "ğŸ”” Checking AlertManager..."
if curl -s http://localhost:9093/-/healthy > /dev/null; then
    echo "  âœ… AlertManager is healthy"
else
    echo "  âŒ AlertManager is not responding"
fi

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸
echo "ğŸ“¡ Checking metric collection..."
METRICS_COUNT=$(curl -s http://localhost:9090/api/v1/label/__name__/values | jq '.data | length')
if [ "$METRICS_COUNT" -gt 10 ]; then
    echo "  âœ… Collecting $METRICS_COUNT metrics"
else
    echo "  âš ï¸  Only collecting $METRICS_COUNT metrics (expected > 10)"
fi

# í™œì„± ì•Œë¦¼ í™•ì¸
echo "ğŸš¨ Checking active alerts..."
ALERTS_COUNT=$(curl -s http://localhost:9093/api/v1/alerts | jq '.data | length')
if [ "$ALERTS_COUNT" -eq 0 ]; then
    echo "  âœ… No active alerts"
else
    echo "  âš ï¸  $ALERTS_COUNT active alerts"
fi

echo ""
echo "ğŸ¯ Monitoring health check completed!"
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. Prometheusê°€ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°
```bash
# íƒ€ê²Ÿ ìƒíƒœ í™•ì¸
curl http://localhost:9090/api/v1/targets

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸ ì§ì ‘ í™•ì¸
curl http://korea-backend:8000/metrics

# ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
docker exec prometheus ping korea-backend
```

#### 2. Grafana ëŒ€ì‹œë³´ë“œê°€ ë°ì´í„°ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠëŠ” ê²½ìš°
```bash
# ë°ì´í„°ì†ŒìŠ¤ ì—°ê²° í™•ì¸
curl -u admin:admin123! http://localhost:3000/api/datasources

# Prometheus ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
curl 'http://localhost:9090/api/v1/query?query=up'

# Grafana ë¡œê·¸ í™•ì¸
docker logs grafana
```

#### 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ì€ ê²½ìš°
```yaml
# prometheus.ymlì—ì„œ retention ì¡°ì •
storage:
  tsdb:
    retention.time: 15d  # 30dì—ì„œ 15dë¡œ ê°ì†Œ
    retention.size: 5GB  # 10GBì—ì„œ 5GBë¡œ ê°ì†Œ
```

#### 4. ë†’ì€ ì¹´ë””ë„ë¦¬í‹° ë©”íŠ¸ë¦­ ì²˜ë¦¬
```yaml
# ë©”íŠ¸ë¦­ í•„í„°ë§ ì„¤ì •
metric_relabel_configs:
  - source_labels: [__name__]
    regex: 'high_cardinality_metric_.*'
    action: drop
  
  - source_labels: [user_id]
    regex: '.*'
    action: drop  # user_id ë ˆì´ë¸” ì œê±°
```

### ë¡œê·¸ ë° ë””ë²„ê¹…
```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸
docker-compose -f docker-compose.monitoring.yml logs -f

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸
docker logs prometheus -f
docker logs grafana -f
docker logs alertmanager -f

# ë©”íŠ¸ë¦­ í™•ì¸
curl http://localhost:9090/metrics | grep prometheus_

# ì„¤ì • ë‹¤ì‹œ ë¡œë“œ
curl -X POST http://localhost:9090/-/reload
```

### ë°±ì—… ë° ë³µì›
```bash
#!/bin/bash
# scripts/backup_monitoring.sh

BACKUP_DIR="/backup/monitoring"
DATE=$(date +%Y%m%d_%H%M%S)

# Prometheus ë°ì´í„° ë°±ì—…
docker run --rm -v prometheus_data:/data -v $BACKUP_DIR:/backup \
  alpine tar czf /backup/prometheus_$DATE.tar.gz -C /data .

# Grafana ë°ì´í„° ë°±ì—…
docker run --rm -v grafana_data:/data -v $BACKUP_DIR:/backup \
  alpine tar czf /backup/grafana_$DATE.tar.gz -C /data .

echo "âœ… Backup completed: $BACKUP_DIR"
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ëª¨ë“  ì„¤ì • íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ê°€?
- [ ] ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì´ ì˜¬ë°”ë¥¸ê°€?
- [ ] ë³¼ë¥¨ ë§ˆìš´íŠ¸ê°€ ì˜¬ë°”ë¥¸ê°€?
- [ ] í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ê°€?
- [ ] ë³´ì•ˆ ì„¤ì • (íŒ¨ìŠ¤ì›Œë“œ, í† í°)ì´ ì ì ˆí•œê°€?

### ìš´ì˜ ì¤‘ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì •ìƒ ë™ì‘í•˜ëŠ”ê°€?
- [ ] ë©”íŠ¸ë¦­ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì§‘ë˜ê³  ìˆëŠ”ê°€?
- [ ] ëŒ€ì‹œë³´ë“œê°€ ë°ì´í„°ë¥¼ í‘œì‹œí•˜ëŠ”ê°€?
- [ ] ì•Œë¦¼ì´ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ê°€?
- [ ] ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ì¹˜ ì´í•˜ì¸ê°€?

### ì •ê¸° ì ê²€ ì‚¬í•­
- [ ] ë©”íŠ¸ë¦­ ë³´ì¡´ ì •ì±… ê²€í† 
- [ ] ì•Œë¦¼ ê·œì¹™ íš¨ê³¼ì„± ê²€í† 
- [ ] ëŒ€ì‹œë³´ë“œ ì‚¬ìš© íŒ¨í„´ ë¶„ì„
- [ ] ì„±ëŠ¥ ìµœì í™” ê¸°íšŒ ì‹ë³„
- [ ] ë³´ì•ˆ ì—…ë°ì´íŠ¸ ì ìš©

## ğŸ”„ ì—…ë°ì´íŠ¸ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ì‚¬í•­ | ì‘ì„±ì |
|------|------|----------|--------|
| 1.0.0 | 2025-08-14 | ì´ˆê¸° Prometheus/Grafana ëª¨ë‹ˆí„°ë§ ì„¤ì • ë¬¸ì„œ ì‘ì„± | DevOps Team |

---

*ì´ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì€ Korea Public Data í”„ë¡œì íŠ¸ì˜ ì•ˆì •ì ì¸ ìš´ì˜ê³¼ ì§€ì†ì ì¸ ê°œì„ ì„ ìœ„í•œ í•µì‹¬ ì¸í”„ë¼ì…ë‹ˆë‹¤. ì •ê¸°ì ì¸ ì ê²€ê³¼ ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ ìµœì ì˜ ëª¨ë‹ˆí„°ë§ í™˜ê²½ì„ ìœ ì§€í•˜ê² ìŠµë‹ˆë‹¤.*