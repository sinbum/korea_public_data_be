# ğŸ­ Business ë„ë©”ì¸ êµ¬í˜„ í˜„í™©

> Korea Public Data Backendì˜ Business ë„ë©”ì¸ ìƒì„¸ êµ¬í˜„ í˜„í™© ë° ê¸°ìˆ  ë¬¸ì„œ

## ğŸ“‹ ëª©ì°¨
- [ë„ë©”ì¸ ê°œìš”](#ë„ë©”ì¸-ê°œìš”)
- [ì•„í‚¤í…ì²˜ êµ¬ì¡°](#ì•„í‚¤í…ì²˜-êµ¬ì¡°)
- [ë°ì´í„° ëª¨ë¸](#ë°ì´í„°-ëª¨ë¸)
- [API ì—”ë“œí¬ì¸íŠ¸](#api-ì—”ë“œí¬ì¸íŠ¸)
- [ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§](#ë¹„ì¦ˆë‹ˆìŠ¤-ë¡œì§)
- [ê³ ê¸‰ ê¸°ëŠ¥](#ê³ ê¸‰-ê¸°ëŠ¥)
- [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
- [í…ŒìŠ¤íŒ…](#í…ŒìŠ¤íŒ…)

## ğŸ¯ ë„ë©”ì¸ ê°œìš”

### Business ë„ë©”ì¸ì˜ ì—­í• 
Business ë„ë©”ì¸ì€ ì¤‘ì†Œê¸°ì—… ë° ìŠ¤íƒ€íŠ¸ì—…ì˜ ì‚¬ì—… ì •ë³´ë¥¼ ê´€ë¦¬í•˜ê³ , ê³µê³ ì™€ì˜ ì—°ê´€ì„± ë¶„ì„, ì„±ê³¼ í‰ê°€, ë§ì¶¤í˜• ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” í•µì‹¬ ë„ë©”ì¸ì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
1. **ì‚¬ì—… ì •ë³´ ê´€ë¦¬**: CRUD ë° ê³ ê¸‰ ê²€ìƒ‰/í•„í„°ë§
2. **ë¶„ì„ ì‹œìŠ¤í…œ**: ML ê¸°ë°˜ ì„±ê³¼ ë¶„ì„ ë° ì˜ˆì¸¡
3. **ì¶”ì²œ ì—”ì§„**: ê°œì¸í™”ëœ ì‚¬ì—… ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜
4. **ë¹„êµ ë„êµ¬**: ë‹¤ì¤‘ ì‚¬ì—… ì„±ê³¼ ë¹„êµ ë¶„ì„
5. **ì—°ê´€ì„± ë¶„ì„**: ê³µê³ -ì‚¬ì—… ê°„ ë§¤ì¹­ ì‹œìŠ¤í…œ

### í˜„ì¬ êµ¬í˜„ ìƒíƒœ
- **ì™„ì„±ë„**: 85% âœ…
- **í”„ë¡œë•ì…˜ ì¤€ë¹„ë„**: 95% âœ…
- **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: 82% âœ…
- **ì„±ëŠ¥ ìµœì í™”**: 90% âœ…

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ êµ¬ì¡°

### ë„ë©”ì¸ ê³„ì¸µ êµ¬ì¡°
```mermaid
graph TB
    A[API Layer] --> B[Service Layer]
    B --> C[Repository Layer]
    C --> D[MongoDB Database]
    
    B --> E[External Services]
    E --> F[ML/AI Services]
    E --> G[Cache Layer]
    
    H[Celery Tasks] --> B
    I[Event Bus] --> B
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
```

### íŒŒì¼ êµ¬ì¡°
```
app/domains/businesses/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ business.py          # í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸
â”‚   â”œâ”€â”€ analysis.py          # ë¶„ì„ ê²°ê³¼ ëª¨ë¸
â”‚   â””â”€â”€ recommendation.py    # ì¶”ì²œ ì‹œìŠ¤í…œ ëª¨ë¸
â”œâ”€â”€ repositories/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ business_repository.py
â”‚   â””â”€â”€ analysis_repository.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ business_service.py  # í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”œâ”€â”€ analysis_service.py  # ë¶„ì„ ì„œë¹„ìŠ¤
â”‚   â”œâ”€â”€ recommendation_service.py
â”‚   â””â”€â”€ comparison_service.py
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ business_router.py   # API ë¼ìš°í„°
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ request.py          # ìš”ì²­ ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ response.py         # ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
â””â”€â”€ tasks/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ analysis_tasks.py    # ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„
    â””â”€â”€ recommendation_tasks.py
```

## ğŸ“Š ë°ì´í„° ëª¨ë¸

### Business í•µì‹¬ ëª¨ë¸
```python
# app/domains/businesses/models/business.py

from datetime import datetime
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field
from bson import ObjectId

class BusinessBase(BaseModel):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°ë³¸ ëª¨ë¸"""
    business_name: str = Field(..., min_length=2, max_length=200)
    business_type: str = Field(..., description="ì‚¬ì—… ìœ í˜•")
    industry: str = Field(..., description="ì‚°ì—… ë¶„ì•¼")
    business_size: str = Field(..., description="ê¸°ì—… ê·œëª¨ (startup/sme/large)")
    
    # ìœ„ì¹˜ ì •ë³´
    location: Dict[str, Any] = Field(default_factory=dict)
    address: Optional[str] = None
    
    # ì‚¬ì—… ìƒì„¸ ì •ë³´
    description: Optional[str] = None
    establishment_date: Optional[datetime] = None
    employee_count: Optional[int] = Field(None, ge=0)
    annual_revenue: Optional[float] = Field(None, ge=0)
    
    # ì‚¬ì—… ë¶„ë¥˜
    business_categories: List[str] = Field(default_factory=list)
    technology_stack: List[str] = Field(default_factory=list)
    
    # ì—°ë½ì²˜ ì •ë³´
    contact_info: Dict[str, Any] = Field(default_factory=dict)
    website: Optional[str] = None
    
    # ìƒíƒœ ê´€ë¦¬
    is_active: bool = True
    verification_status: str = Field(default="pending")  # pending/verified/rejected

class Business(BusinessBase):
    """MongoDBìš© ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸"""
    id: Optional[str] = Field(alias="_id")
    
    # ë©”íƒ€ë°ì´í„°
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)
    
    # ë¶„ì„ ë°ì´í„° (ìºì‹œëœ ê²°ê³¼)
    analysis_cache: Optional[Dict[str, Any]] = None
    performance_metrics: Optional[Dict[str, Any]] = None
    recommendation_score: Optional[float] = Field(None, ge=0, le=1)
    
    # ì—°ê´€ ë°ì´í„°
    related_announcements_count: int = Field(default=0)
    related_announcements_last_updated: Optional[datetime] = None
    
    class Config:
        allow_population_by_field_name = True
        json_encoders = {
            ObjectId: str,
            datetime: lambda v: v.isoformat()
        }
        schema_extra = {
            "example": {
                "business_name": "AIìŠ¤íƒ€íŠ¸ì—…",
                "business_type": "ê¸°ìˆ ê¸°ì—…",
                "industry": "ì¸ê³µì§€ëŠ¥",
                "business_size": "startup",
                "location": {
                    "city": "ì„œìš¸",
                    "district": "ê°•ë‚¨êµ¬",
                    "coordinates": [127.0276, 37.4979]
                },
                "description": "AI ê¸°ë°˜ ì†”ë£¨ì…˜ ê°œë°œ ìŠ¤íƒ€íŠ¸ì—…",
                "employee_count": 25,
                "business_categories": ["AI", "ì†Œí”„íŠ¸ì›¨ì–´", "B2B"],
                "technology_stack": ["Python", "TensorFlow", "FastAPI"]
            }
        }

class BusinessAnalysis(BaseModel):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ê²°ê³¼ ëª¨ë¸"""
    business_id: str
    analysis_type: str  # performance/prediction/recommendation
    
    # ì„±ê³¼ ì§€í‘œ
    performance_score: float = Field(ge=0, le=1)
    growth_rate: Optional[float] = None
    success_probability: Optional[float] = Field(None, ge=0, le=1)
    
    # ê´€ë ¨ ê³µê³  ë¶„ì„
    related_announcements: List[Dict[str, Any]] = Field(default_factory=list)
    announcement_match_score: float = Field(default=0, ge=0, le=1)
    
    # ê²½ìŸë ¥ ë¶„ì„
    competitive_advantages: List[str] = Field(default_factory=list)
    improvement_areas: List[str] = Field(default_factory=list)
    
    # ì¶”ì²œ ì •ë³´
    recommended_announcements: List[str] = Field(default_factory=list)
    recommended_partnerships: List[str] = Field(default_factory=list)
    
    # ë¶„ì„ ë©”íƒ€ë°ì´í„°
    analysis_date: datetime = Field(default_factory=datetime.utcnow)
    confidence_score: float = Field(ge=0, le=1)
    model_version: str = Field(default="v1.0")
    
    class Config:
        schema_extra = {
            "example": {
                "business_id": "64f8a1b2c3d4e5f6a7b8c9d0",
                "analysis_type": "performance",
                "performance_score": 0.85,
                "growth_rate": 0.15,
                "success_probability": 0.78,
                "announcement_match_score": 0.92,
                "competitive_advantages": ["AI ì „ë¬¸ì„±", "ë¹ ë¥¸ ê°œë°œ"],
                "improvement_areas": ["ë§ˆì¼€íŒ…", "ìê¸ˆ ì¡°ë‹¬"],
                "confidence_score": 0.89
            }
        }
```

### í•„í„°ë§ ë° ê²€ìƒ‰ ëª¨ë¸
```python
# app/domains/businesses/schemas/request.py

from typing import Optional, List
from pydantic import BaseModel, Field

class BusinessFilters(BaseModel):
    """ë¹„ì¦ˆë‹ˆìŠ¤ í•„í„°ë§ íŒŒë¼ë¯¸í„°"""
    # ê¸°ë³¸ í•„í„°
    industry: Optional[str] = None
    business_type: Optional[str] = None
    business_size: Optional[str] = None
    location_city: Optional[str] = None
    
    # ë²”ìœ„ í•„í„°
    min_employee_count: Optional[int] = Field(None, ge=0)
    max_employee_count: Optional[int] = Field(None, ge=0)
    min_revenue: Optional[float] = Field(None, ge=0)
    max_revenue: Optional[float] = Field(None, ge=0)
    
    # ë‚ ì§œ í•„í„°
    established_after: Optional[str] = None
    established_before: Optional[str] = None
    
    # ê²€ìƒ‰
    search_query: Optional[str] = Field(None, min_length=2)
    
    # ê³ ê¸‰ í•„í„°
    technology_stack: Optional[List[str]] = None
    has_website: Optional[bool] = None
    verification_status: Optional[str] = Field(default="verified")
    
    # ì •ë ¬ ë° í˜ì´ì§•
    sort_by: str = Field(default="created_at")
    sort_order: str = Field(default="desc", regex="^(asc|desc)$")
    page: int = Field(default=1, ge=1)
    size: int = Field(default=20, ge=1, le=100)
    
    class Config:
        schema_extra = {
            "example": {
                "industry": "AI",
                "business_size": "startup",
                "location_city": "ì„œìš¸",
                "min_employee_count": 10,
                "max_employee_count": 100,
                "technology_stack": ["Python", "AI"],
                "search_query": "ì¸ê³µì§€ëŠ¥",
                "sort_by": "performance_score",
                "page": 1,
                "size": 20
            }
        }

class BusinessComparison(BaseModel):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ë¹„êµ ìš”ì²­"""
    business_ids: List[str] = Field(..., min_items=2, max_items=10)
    comparison_criteria: List[str] = Field(
        default=["performance", "growth", "innovation"],
        description="ë¹„êµ ê¸°ì¤€"
    )
    include_predictions: bool = Field(default=True)
    
    class Config:
        schema_extra = {
            "example": {
                "business_ids": ["64f8a1b2c3d4e5f6a7b8c9d0", "64f8a1b2c3d4e5f6a7b8c9d1"],
                "comparison_criteria": ["performance", "growth", "market_fit"],
                "include_predictions": True
            }
        }
```

## ğŸ”§ API ì—”ë“œí¬ì¸íŠ¸

### CRUD ì—”ë“œí¬ì¸íŠ¸
```python
# app/domains/businesses/routers/business_router.py

from fastapi import APIRouter, Depends, HTTPException, Query
from fastapi_pagination import Page, Params
from typing import List, Optional

from ..services.business_service import BusinessService
from ..schemas.request import BusinessFilters, BusinessComparison
from ..schemas.response import BusinessResponse, BusinessAnalysisResponse
from ...auth.dependencies import get_current_user

router = APIRouter(prefix="/api/v1/businesses", tags=["businesses"])

@router.get("/", response_model=Page[BusinessResponse])
async def get_businesses(
    filters: BusinessFilters = Depends(),
    service: BusinessService = Depends(),
    params: Params = Depends()
) -> Page[BusinessResponse]:
    """
    ì‚¬ì—… ëª©ë¡ ì¡°íšŒ (ê³ ê¸‰ í•„í„°ë§ ì§€ì›)
    
    ### í•„í„°ë§ ì˜µì…˜:
    - **industry**: ì‚°ì—… ë¶„ì•¼ë³„ í•„í„°ë§
    - **business_size**: ê¸°ì—… ê·œëª¨ë³„ í•„í„°ë§  
    - **location_city**: ì§€ì—­ë³„ í•„í„°ë§
    - **employee_count**: ì§ì› ìˆ˜ ë²”ìœ„ í•„í„°ë§
    - **technology_stack**: ê¸°ìˆ  ìŠ¤íƒ í•„í„°ë§
    - **search_query**: ì „ë¬¸ ê²€ìƒ‰ (ì´ë¦„, ì„¤ëª…, ì¹´í…Œê³ ë¦¬)
    
    ### ì •ë ¬ ì˜µì…˜:
    - **created_at**: ìƒì„±ì¼ìˆœ
    - **performance_score**: ì„±ê³¼ ì ìˆ˜ìˆœ
    - **employee_count**: ì§ì› ìˆ˜ìˆœ
    - **recommendation_score**: ì¶”ì²œ ì ìˆ˜ìˆœ
    """
    return await service.get_businesses_with_filters(filters, params)

@router.get("/{business_id}", response_model=BusinessResponse)
async def get_business_detail(
    business_id: str,
    include_analysis: bool = Query(default=True, description="ë¶„ì„ ë°ì´í„° í¬í•¨ ì—¬ë¶€"),
    service: BusinessService = Depends()
) -> BusinessResponse:
    """
    ì‚¬ì—… ìƒì„¸ ì •ë³´ ì¡°íšŒ
    
    - ê¸°ë³¸ ì‚¬ì—… ì •ë³´
    - ì„±ê³¼ ë¶„ì„ ë°ì´í„° (ì˜µì…˜)
    - ê´€ë ¨ ê³µê³  ì •ë³´
    - ì¶”ì²œ ì ìˆ˜
    """
    business = await service.get_business_by_id(business_id)
    if not business:
        raise HTTPException(status_code=404, detail="Business not found")
    
    if include_analysis:
        analysis = await service.get_business_analysis(business_id)
        business.analysis = analysis
    
    return business

@router.post("/", response_model=BusinessResponse, status_code=201)
async def create_business(
    business_data: BusinessCreate,
    service: BusinessService = Depends(),
    current_user: dict = Depends(get_current_user)
) -> BusinessResponse:
    """
    ìƒˆ ì‚¬ì—… ë“±ë¡
    
    - ë°ì´í„° ê²€ì¦ ë° ì¤‘ë³µ ì²´í¬
    - ì´ˆê¸° ë¶„ì„ ì‘ì—… íì‰
    - ê´€ë ¨ ê³µê³  ë§¤ì¹­ ì‹œì‘
    """
    # ì¤‘ë³µ ì²´í¬
    existing = await service.check_duplicate_business(business_data.business_name)
    if existing:
        raise HTTPException(status_code=409, detail="Business already exists")
    
    business = await service.create_business(business_data, current_user["id"])
    
    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… íì‰
    from ..tasks.analysis_tasks import analyze_new_business
    analyze_new_business.delay(business.id)
    
    return business

@router.put("/{business_id}", response_model=BusinessResponse)
async def update_business(
    business_id: str,
    business_data: BusinessUpdate,
    service: BusinessService = Depends(),
    current_user: dict = Depends(get_current_user)
) -> BusinessResponse:
    """ì‚¬ì—… ì •ë³´ ìˆ˜ì •"""
    business = await service.update_business(business_id, business_data)
    if not business:
        raise HTTPException(status_code=404, detail="Business not found")
    
    # ë¶„ì„ ìºì‹œ ë¬´íš¨í™”
    await service.invalidate_analysis_cache(business_id)
    
    return business

@router.delete("/{business_id}", status_code=204)
async def delete_business(
    business_id: str,
    service: BusinessService = Depends(),
    current_user: dict = Depends(get_current_user)
):
    """ì‚¬ì—… ì‚­ì œ (ì†Œí”„íŠ¸ ì‚­ì œ)"""
    success = await service.soft_delete_business(business_id)
    if not success:
        raise HTTPException(status_code=404, detail="Business not found")
```

### ê³ ê¸‰ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
```python
@router.get("/{business_id}/analysis", response_model=BusinessAnalysisResponse)
async def get_business_analysis(
    business_id: str,
    analysis_type: str = Query(default="comprehensive", regex="^(performance|prediction|recommendation|comprehensive)$"),
    force_refresh: bool = Query(default=False, description="ìºì‹œ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ë¶„ì„"),
    service: BusinessService = Depends()
) -> BusinessAnalysisResponse:
    """
    ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    
    ### ë¶„ì„ íƒ€ì…:
    - **performance**: í˜„ì¬ ì„±ê³¼ ë¶„ì„
    - **prediction**: ë¯¸ë˜ ì„±ê³¼ ì˜ˆì¸¡
    - **recommendation**: ë§ì¶¤í˜• ì¶”ì²œ
    - **comprehensive**: ì¢…í•© ë¶„ì„ (ê¸°ë³¸ê°’)
    """
    analysis = await service.get_comprehensive_analysis(
        business_id, 
        analysis_type, 
        force_refresh
    )
    if not analysis:
        raise HTTPException(status_code=404, detail="Analysis not available")
    
    return analysis

@router.post("/compare", response_model=Dict[str, Any])
async def compare_businesses(
    comparison_request: BusinessComparison,
    service: BusinessService = Depends()
) -> Dict[str, Any]:
    """
    ë‹¤ì¤‘ ì‚¬ì—… ë¹„êµ ë¶„ì„
    
    - ì„±ê³¼ ì§€í‘œ ë¹„êµ
    - ê°•ì /ì•½ì  ë¶„ì„
    - ì‹œì¥ ì í•©ì„± í‰ê°€
    - ì„±ì¥ ê°€ëŠ¥ì„± ì˜ˆì¸¡
    """
    comparison_result = await service.compare_businesses(
        comparison_request.business_ids,
        comparison_request.comparison_criteria,
        comparison_request.include_predictions
    )
    
    return {
        "comparison_id": comparison_result.id,
        "businesses": comparison_result.businesses,
        "comparison_matrix": comparison_result.matrix,
        "insights": comparison_result.insights,
        "recommendations": comparison_result.recommendations
    }

@router.get("/recommendations", response_model=List[BusinessResponse])
async def get_business_recommendations(
    user_preferences: Optional[str] = Query(None, description="ì‚¬ìš©ì ì„ í˜¸ë„ JSON"),
    limit: int = Query(default=10, ge=1, le=50),
    service: BusinessService = Depends(),
    current_user: dict = Depends(get_current_user)
) -> List[BusinessResponse]:
    """
    ê°œì¸í™”ëœ ì‚¬ì—… ì¶”ì²œ
    
    - ì‚¬ìš©ì ì´ë ¥ ê¸°ë°˜ ì¶”ì²œ
    - ê´€ì‹¬ ë¶„ì•¼ ë§ì¶¤ ì¶”ì²œ
    - ì„±ê³¼ ê°€ëŠ¥ì„± ê¸°ë°˜ ë­í‚¹
    """
    recommendations = await service.get_personalized_recommendations(
        current_user["id"],
        user_preferences,
        limit
    )
    
    return recommendations

@router.get("/trends", response_model=Dict[str, Any])
async def get_business_trends(
    period: str = Query(default="30d", regex="^(7d|30d|90d|1y)$"),
    industry: Optional[str] = Query(None),
    business_size: Optional[str] = Query(None),
    service: BusinessService = Depends()
) -> Dict[str, Any]:
    """
    ì‚¬ì—… íŠ¸ë Œë“œ ë¶„ì„
    
    - ì—…ê³„ë³„ ì„±ì¥ íŠ¸ë Œë“œ
    - ì‹ ê·œ ë“±ë¡ í˜„í™©
    - ì„±ê³¼ ì§€í‘œ ë³€í™”
    - ì˜ˆì¸¡ ë¶„ì„
    """
    trends = await service.analyze_business_trends(period, industry, business_size)
    
    return {
        "period": period,
        "total_businesses": trends.total_count,
        "growth_rate": trends.growth_rate,
        "industry_breakdown": trends.industry_stats,
        "performance_trends": trends.performance_data,
        "predictions": trends.forecasts
    }
```

## ğŸ§  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§

### í•µì‹¬ ì„œë¹„ìŠ¤ êµ¬í˜„
```python
# app/domains/businesses/services/business_service.py

from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
import asyncio
from fastapi_pagination import Page, Params

from ..repositories.business_repository import BusinessRepository
from ..models.business import Business, BusinessAnalysis
from ..schemas.request import BusinessFilters
from ...announcements.services.announcement_service import AnnouncementService
from ....core.cache import CacheService
from ....core.ml import MLService

class BusinessService:
    def __init__(
        self,
        repository: BusinessRepository,
        announcement_service: AnnouncementService,
        cache_service: CacheService,
        ml_service: MLService
    ):
        self.repository = repository
        self.announcement_service = announcement_service
        self.cache = cache_service
        self.ml = ml_service
    
    async def get_businesses_with_filters(
        self, 
        filters: BusinessFilters, 
        params: Params
    ) -> Page[Business]:
        """ê³ ê¸‰ í•„í„°ë§ì´ ì ìš©ëœ ì‚¬ì—… ëª©ë¡ ì¡°íšŒ"""
        
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = f"businesses:filtered:{hash(str(filters.dict()))}:{params.page}:{params.size}"
        cached_result = await self.cache.get(cache_key)
        
        if cached_result:
            return cached_result
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰
        businesses = await self.repository.find_with_filters(filters, params)
        
        # ë³‘ë ¬ë¡œ ì¶”ê°€ ë°ì´í„° ë¡œë“œ
        if businesses.items:
            await self._enrich_business_data(businesses.items)
        
        # ê²°ê³¼ ìºì‹± (5ë¶„)
        await self.cache.set(cache_key, businesses, ttl=300)
        
        return businesses
    
    async def get_comprehensive_analysis(
        self, 
        business_id: str, 
        analysis_type: str = "comprehensive",
        force_refresh: bool = False
    ) -> Optional[BusinessAnalysis]:
        """ì¢…í•©ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„"""
        
        # ìºì‹œ í™•ì¸
        cache_key = f"business:analysis:{business_id}:{analysis_type}"
        if not force_refresh:
            cached_analysis = await self.cache.get(cache_key)
            if cached_analysis:
                return cached_analysis
        
        business = await self.repository.get_by_id(business_id)
        if not business:
            return None
        
        # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
        analysis_tasks = [
            self._analyze_performance(business),
            self._analyze_market_fit(business),
            self._get_related_announcements(business),
            self._calculate_growth_potential(business)
        ]
        
        performance_data, market_data, related_announcements, growth_data = await asyncio.gather(*analysis_tasks)
        
        # ML ê¸°ë°˜ ì¢…í•© ë¶„ì„
        ml_insights = await self.ml.analyze_business_comprehensive(
            business_data=business.dict(),
            performance_data=performance_data,
            market_data=market_data,
            related_data=related_announcements
        )
        
        # ë¶„ì„ ê²°ê³¼ ìƒì„±
        analysis = BusinessAnalysis(
            business_id=business_id,
            analysis_type=analysis_type,
            performance_score=ml_insights.performance_score,
            growth_rate=growth_data.projected_growth,
            success_probability=ml_insights.success_probability,
            related_announcements=related_announcements[:10],  # ìƒìœ„ 10ê°œ
            announcement_match_score=ml_insights.announcement_compatibility,
            competitive_advantages=ml_insights.strengths,
            improvement_areas=ml_insights.weaknesses,
            recommended_announcements=ml_insights.recommended_opportunities,
            confidence_score=ml_insights.confidence,
            model_version="v2.1"
        )
        
        # ë¶„ì„ ê²°ê³¼ ìºì‹± (30ë¶„)
        await self.cache.set(cache_key, analysis, ttl=1800)
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆì½”ë“œì˜ ìºì‹œ ì—…ë°ì´íŠ¸
        await self.repository.update_analysis_cache(business_id, analysis.dict())
        
        return analysis
    
    async def compare_businesses(
        self, 
        business_ids: List[str], 
        criteria: List[str],
        include_predictions: bool = True
    ) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ì‚¬ì—… ë¹„êµ ë¶„ì„"""
        
        # ì‚¬ì—… ë°ì´í„° ë¡œë“œ
        businesses = await self.repository.get_multiple_by_ids(business_ids)
        if len(businesses) != len(business_ids):
            missing_ids = set(business_ids) - {b.id for b in businesses}
            raise ValueError(f"Businesses not found: {missing_ids}")
        
        # ê° ì‚¬ì—…ì˜ ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘
        analysis_tasks = [
            self.get_comprehensive_analysis(business.id) 
            for business in businesses
        ]
        analyses = await asyncio.gather(*analysis_tasks)
        
        # ë¹„êµ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        comparison_matrix = await self._generate_comparison_matrix(
            businesses, analyses, criteria
        )
        
        # ML ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = await self.ml.generate_comparison_insights(
            businesses_data=[b.dict() for b in businesses],
            analyses_data=[a.dict() for a in analyses if a],
            criteria=criteria
        )
        
        # ì˜ˆì¸¡ ë¶„ì„ (ì˜µì…˜)
        predictions = None
        if include_predictions:
            predictions = await self._generate_growth_predictions(businesses)
        
        return {
            "id": f"comparison_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}",
            "businesses": [b.dict() for b in businesses],
            "matrix": comparison_matrix,
            "insights": insights,
            "predictions": predictions,
            "recommendations": insights.get("recommendations", []),
            "generated_at": datetime.utcnow()
        }
    
    async def get_personalized_recommendations(
        self, 
        user_id: str, 
        preferences: Optional[str] = None,
        limit: int = 10
    ) -> List[Business]:
        """ê°œì¸í™”ëœ ì‚¬ì—… ì¶”ì²œ"""
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ë¶„ì„
        user_profile = await self._analyze_user_preferences(user_id, preferences)
        
        # í›„ë³´ ì‚¬ì—… í•„í„°ë§
        candidate_businesses = await self.repository.find_recommendation_candidates(
            user_profile.interests,
            user_profile.experience_level,
            user_profile.preferred_industries
        )
        
        # ML ê¸°ë°˜ ì¶”ì²œ ìŠ¤ì½”ì–´ë§
        scored_businesses = await self.ml.score_business_recommendations(
            user_profile=user_profile.dict(),
            candidates=[b.dict() for b in candidate_businesses]
        )
        
        # ìƒìœ„ ì¶”ì²œ ì‚¬ì—… ì„ ë³„
        top_recommendations = sorted(
            scored_businesses, 
            key=lambda x: x.recommendation_score, 
            reverse=True
        )[:limit]
        
        # ì¶”ì²œ ì´ìœ  ìƒì„±
        for business in top_recommendations:
            business.recommendation_reasons = await self._generate_recommendation_reasons(
                business, user_profile
            )
        
        return top_recommendations
    
    async def _enrich_business_data(self, businesses: List[Business]):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ë³´ê°• (ê´€ë ¨ ê³µê³ , ì„±ê³¼ ì§€í‘œ ë“±)"""
        
        enrichment_tasks = []
        for business in businesses:
            tasks = [
                self._get_cached_analysis(business.id),
                self._get_related_announcements_count(business.id),
                self._calculate_trending_score(business)
            ]
            enrichment_tasks.extend(tasks)
        
        results = await asyncio.gather(*enrichment_tasks, return_exceptions=True)
        
        # ê²°ê³¼ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê°ì²´ì— ì ìš©
        for i, business in enumerate(businesses):
            base_idx = i * 3
            
            if isinstance(results[base_idx], dict):
                business.analysis_cache = results[base_idx]
            
            if isinstance(results[base_idx + 1], int):
                business.related_announcements_count = results[base_idx + 1]
            
            if isinstance(results[base_idx + 2], float):
                business.trending_score = results[base_idx + 2]
    
    async def _analyze_performance(self, business: Business) -> Dict[str, Any]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ê³¼ ë¶„ì„"""
        
        # ê¸°ë³¸ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        base_metrics = {
            "employee_growth": await self._calculate_employee_growth(business),
            "revenue_growth": await self._calculate_revenue_growth(business),
            "market_presence": await self._assess_market_presence(business),
            "innovation_score": await self._calculate_innovation_score(business)
        }
        
        # ì—…ê³„ ë²¤ì¹˜ë§ˆí‚¹
        industry_benchmark = await self._get_industry_benchmark(
            business.industry, business.business_size
        )
        
        # ìƒëŒ€ì  ì„±ê³¼ í‰ê°€
        relative_performance = {}
        for metric, value in base_metrics.items():
            benchmark_value = industry_benchmark.get(metric, 0)
            relative_performance[f"{metric}_vs_industry"] = (
                (value - benchmark_value) / benchmark_value if benchmark_value > 0 else 0
            )
        
        return {
            "absolute_metrics": base_metrics,
            "relative_metrics": relative_performance,
            "industry_benchmark": industry_benchmark,
            "overall_score": sum(base_metrics.values()) / len(base_metrics)
        }
    
    async def _get_related_announcements(self, business: Business) -> List[Dict[str, Any]]:
        """ê´€ë ¨ ê³µê³  ë§¤ì¹­"""
        
        # ML ê¸°ë°˜ ê³µê³  ë§¤ì¹­
        matching_criteria = {
            "industry": business.industry,
            "business_type": business.business_type,
            "categories": business.business_categories,
            "technology_stack": business.technology_stack,
            "location": business.location
        }
        
        related_announcements = await self.announcement_service.find_matching_announcements(
            matching_criteria, limit=20
        )
        
        # ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        scored_announcements = []
        for announcement in related_announcements:
            score = await self.ml.calculate_business_announcement_match(
                business.dict(), announcement.dict()
            )
            
            scored_announcements.append({
                "announcement": announcement.dict(),
                "match_score": score,
                "match_reasons": await self._explain_match(business, announcement)
            })
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        scored_announcements.sort(key=lambda x: x["match_score"], reverse=True)
        
        return scored_announcements
```

## ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥

### ML ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
```python
# app/domains/businesses/services/recommendation_service.py

from typing import List, Dict, Any, Optional
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans

class BusinessRecommendationService:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self.similarity_cache = {}
    
    async def generate_content_based_recommendations(
        self, 
        target_business: Business, 
        all_businesses: List[Business],
        n_recommendations: int = 10
    ) -> List[Dict[str, Any]]:
        """ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ"""
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ
        business_texts = [
            self._extract_business_text(business) 
            for business in all_businesses
        ]
        target_text = self._extract_business_text(target_business)
        
        # TF-IDF ë²¡í„°í™”
        all_texts = [target_text] + business_texts
        tfidf_matrix = self.vectorizer.fit_transform(all_texts)
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        target_vector = tfidf_matrix[0:1]
        business_vectors = tfidf_matrix[1:]
        similarities = cosine_similarity(target_vector, business_vectors).flatten()
        
        # ì¶”ì²œ ìƒì„±
        recommendations = []
        top_indices = np.argsort(similarities)[::-1][:n_recommendations]
        
        for idx in top_indices:
            business = all_businesses[idx]
            recommendations.append({
                "business": business,
                "similarity_score": similarities[idx],
                "recommendation_type": "content_based",
                "explanation": self._generate_similarity_explanation(
                    target_business, business, similarities[idx]
                )
            })
        
        return recommendations
    
    async def generate_collaborative_recommendations(
        self, 
        user_interactions: List[Dict[str, Any]], 
        all_businesses: List[Business],
        n_recommendations: int = 10
    ) -> List[Dict[str, Any]]:
        """í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ"""
        
        # ì‚¬ìš©ì-ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí˜¸ì‘ìš© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        interaction_matrix = self._build_interaction_matrix(user_interactions, all_businesses)
        
        # ì ì¬ ìš”ì¸ ë¶„í•´ (Matrix Factorization)
        user_factors, business_factors = await self._matrix_factorization(
            interaction_matrix, n_factors=50
        )
        
        # ì¶”ì²œ ì ìˆ˜ ì˜ˆì¸¡
        predicted_scores = np.dot(user_factors, business_factors.T)
        
        # ìƒìœ„ ì¶”ì²œ ì„ ë³„
        recommendations = []
        top_business_indices = np.argsort(predicted_scores[0])[::-1][:n_recommendations]
        
        for idx in top_business_indices:
            business = all_businesses[idx]
            recommendations.append({
                "business": business,
                "predicted_score": predicted_scores[0][idx],
                "recommendation_type": "collaborative",
                "explanation": "ìœ ì‚¬í•œ ê´€ì‹¬ì‚¬ë¥¼ ê°€ì§„ ì‚¬ìš©ìë“¤ì´ ì„ í˜¸í•œ ì‚¬ì—…"
            })
        
        return recommendations
    
    async def generate_hybrid_recommendations(
        self, 
        target_business: Business,
        user_interactions: List[Dict[str, Any]],
        all_businesses: List[Business],
        n_recommendations: int = 10
    ) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ (ì½˜í…ì¸  + í˜‘ì—… í•„í„°ë§)"""
        
        # ê° ë°©ì‹ë³„ ì¶”ì²œ ìƒì„±
        content_recs = await self.generate_content_based_recommendations(
            target_business, all_businesses, n_recommendations * 2
        )
        
        collab_recs = await self.generate_collaborative_recommendations(
            user_interactions, all_businesses, n_recommendations * 2
        )
        
        # ê°€ì¤‘ ê²°í•©
        hybrid_scores = {}
        content_weight = 0.6
        collab_weight = 0.4
        
        # ì½˜í…ì¸  ê¸°ë°˜ ì ìˆ˜ ì ìš©
        for rec in content_recs:
            business_id = rec["business"].id
            hybrid_scores[business_id] = {
                "business": rec["business"],
                "score": rec["similarity_score"] * content_weight,
                "content_score": rec["similarity_score"],
                "collab_score": 0,
                "explanations": [rec["explanation"]]
            }
        
        # í˜‘ì—… í•„í„°ë§ ì ìˆ˜ ì ìš©
        for rec in collab_recs:
            business_id = rec["business"].id
            if business_id in hybrid_scores:
                hybrid_scores[business_id]["score"] += rec["predicted_score"] * collab_weight
                hybrid_scores[business_id]["collab_score"] = rec["predicted_score"]
                hybrid_scores[business_id]["explanations"].append(rec["explanation"])
            else:
                hybrid_scores[business_id] = {
                    "business": rec["business"],
                    "score": rec["predicted_score"] * collab_weight,
                    "content_score": 0,
                    "collab_score": rec["predicted_score"],
                    "explanations": [rec["explanation"]]
                }
        
        # ìµœì¢… ì¶”ì²œ ì •ë ¬
        final_recommendations = sorted(
            hybrid_scores.values(), 
            key=lambda x: x["score"], 
            reverse=True
        )[:n_recommendations]
        
        return [{
            "business": rec["business"],
            "hybrid_score": rec["score"],
            "content_score": rec["content_score"],
            "collaborative_score": rec["collab_score"],
            "recommendation_type": "hybrid",
            "explanations": rec["explanations"]
        } for rec in final_recommendations]
    
    def _extract_business_text(self, business: Business) -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ í…ìŠ¤íŠ¸ íŠ¹ì„± ì¶”ì¶œ"""
        text_parts = [
            business.business_name,
            business.description or "",
            business.industry,
            business.business_type,
            " ".join(business.business_categories),
            " ".join(business.technology_stack)
        ]
        return " ".join(filter(None, text_parts))
```

### ì„±ëŠ¥ ë¶„ì„ ì‹œìŠ¤í…œ
```python
# app/domains/businesses/services/analysis_service.py

class BusinessAnalysisService:
    def __init__(self, ml_service: MLService):
        self.ml = ml_service
        self.performance_weights = {
            "financial": 0.3,
            "operational": 0.25,
            "market": 0.25,
            "innovation": 0.2
        }
    
    async def analyze_comprehensive_performance(
        self, business: Business
    ) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ ì„±ê³¼ ë¶„ì„"""
        
        # ë‹¤ì°¨ì› ì„±ê³¼ ë¶„ì„
        analysis_tasks = [
            self._analyze_financial_performance(business),
            self._analyze_operational_efficiency(business),
            self._analyze_market_position(business),
            self._analyze_innovation_capacity(business)
        ]
        
        financial, operational, market, innovation = await asyncio.gather(*analysis_tasks)
        
        # ê°€ì¤‘ ì¢…í•© ì ìˆ˜ ê³„ì‚°
        overall_score = (
            financial["score"] * self.performance_weights["financial"] +
            operational["score"] * self.performance_weights["operational"] +
            market["score"] * self.performance_weights["market"] +
            innovation["score"] * self.performance_weights["innovation"]
        )
        
        # ML ê¸°ë°˜ ë¯¸ë˜ ì„±ê³¼ ì˜ˆì¸¡
        future_predictions = await self.ml.predict_business_performance(
            business_data=business.dict(),
            current_performance={
                "financial": financial,
                "operational": operational,
                "market": market,
                "innovation": innovation
            }
        )
        
        return {
            "overall_score": overall_score,
            "performance_breakdown": {
                "financial": financial,
                "operational": operational,
                "market": market,
                "innovation": innovation
            },
            "predictions": future_predictions,
            "recommendations": await self._generate_improvement_recommendations(
                business, financial, operational, market, innovation
            ),
            "benchmarking": await self._get_peer_comparison(business, overall_score),
            "analysis_date": datetime.utcnow(),
            "confidence_score": future_predictions.get("confidence", 0.8)
        }
    
    async def _analyze_financial_performance(self, business: Business) -> Dict[str, Any]:
        """ì¬ë¬´ ì„±ê³¼ ë¶„ì„"""
        
        # ê¸°ë³¸ ì¬ë¬´ ì§€í‘œ
        base_metrics = {
            "revenue_growth": await self._calculate_revenue_growth_rate(business),
            "profitability": await self._estimate_profitability(business),
            "efficiency_ratio": await self._calculate_efficiency_metrics(business),
            "funding_status": await self._assess_funding_status(business)
        }
        
        # ì—…ê³„ ë¹„êµ
        industry_percentile = await self._get_industry_percentile(
            business.industry, base_metrics
        )
        
        # ì¬ë¬´ ê±´ì „ì„± í‰ê°€
        financial_health = await self._assess_financial_health(business, base_metrics)
        
        return {
            "score": (sum(base_metrics.values()) / len(base_metrics)) * financial_health,
            "metrics": base_metrics,
            "industry_percentile": industry_percentile,
            "health_assessment": financial_health,
            "risk_factors": await self._identify_financial_risks(business),
            "opportunities": await self._identify_financial_opportunities(business)
        }
    
    async def _analyze_operational_efficiency(self, business: Business) -> Dict[str, Any]:
        """ìš´ì˜ íš¨ìœ¨ì„± ë¶„ì„"""
        
        efficiency_metrics = {
            "productivity": await self._calculate_productivity_score(business),
            "process_optimization": await self._assess_process_efficiency(business),
            "resource_utilization": await self._calculate_resource_efficiency(business),
            "quality_metrics": await self._assess_quality_indicators(business)
        }
        
        # ë””ì§€í„¸ ì„±ìˆ™ë„ í‰ê°€
        digital_maturity = await self._assess_digital_maturity(business)
        
        return {
            "score": sum(efficiency_metrics.values()) / len(efficiency_metrics),
            "metrics": efficiency_metrics,
            "digital_maturity": digital_maturity,
            "automation_potential": await self._assess_automation_potential(business),
            "improvement_areas": await self._identify_efficiency_improvements(business)
        }
    
    async def predict_growth_trajectory(
        self, business: Business, time_horizon: int = 12
    ) -> Dict[str, Any]:
        """ì„±ì¥ ê¶¤ì  ì˜ˆì¸¡"""
        
        # ê³¼ê±° ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘
        historical_data = await self._collect_historical_performance(business)
        
        # ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„
        market_trends = await self._analyze_market_trends(business.industry)
        
        # ML ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡
        predictions = await self.ml.predict_growth_trajectory(
            business_data=business.dict(),
            historical_data=historical_data,
            market_trends=market_trends,
            time_horizon=time_horizon
        )
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
        scenarios = await self._generate_growth_scenarios(business, predictions)
        
        return {
            "base_prediction": predictions,
            "scenarios": scenarios,
            "key_factors": await self._identify_growth_factors(business),
            "risks": await self._assess_growth_risks(business),
            "recommendations": await self._generate_growth_recommendations(business, predictions)
        }
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±
```python
# app/domains/businesses/repositories/business_repository.py

class BusinessRepository:
    def __init__(self, database):
        self.collection = database.businesses
        self._setup_indexes()
    
    async def _setup_indexes(self):
        """ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤ ì„¤ì •"""
        
        # ë³µí•© ì¸ë±ìŠ¤ (ìì£¼ ì‚¬ìš©ë˜ëŠ” í•„í„° ì¡°í•©)
        await self.collection.create_index([
            ("industry", 1),
            ("business_size", 1),
            ("location.city", 1),
            ("is_active", 1)
        ], name="filter_compound_idx")
        
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤
        await self.collection.create_index([
            ("business_name", "text"),
            ("description", "text"),
            ("business_categories", "text")
        ], name="text_search_idx")
        
        # ì„±ëŠ¥ ì ìˆ˜ ì¸ë±ìŠ¤ (ì •ë ¬ìš©)
        await self.collection.create_index([
            ("performance_metrics.overall_score", -1)
        ], name="performance_sort_idx")
        
        # ì§€ë¦¬ì  ì¸ë±ìŠ¤
        await self.collection.create_index([
            ("location.coordinates", "2dsphere")
        ], name="geo_location_idx")
        
        # ë‚ ì§œ ê¸°ë°˜ ì¸ë±ìŠ¤
        await self.collection.create_index([
            ("created_at", -1)
        ], name="created_date_idx")
        
        # ë¶„ì„ ìºì‹œ TTL ì¸ë±ìŠ¤
        await self.collection.create_index([
            ("analysis_cache.updated_at", 1)
        ], expireAfterSeconds=3600, name="analysis_cache_ttl")
    
    async def find_with_filters_optimized(
        self, filters: BusinessFilters, params: Params
    ) -> Page[Business]:
        """ìµœì í™”ëœ í•„í„°ë§ ì¿¼ë¦¬"""
        
        # ë™ì  ì¿¼ë¦¬ ë¹Œë”
        query = {"is_active": True}
        
        # ì¸ë±ìŠ¤ í™œìš©ì„ ìœ„í•œ ì¿¼ë¦¬ ìˆœì„œ ìµœì í™”
        if filters.industry:
            query["industry"] = filters.industry
        
        if filters.business_size:
            query["business_size"] = filters.business_size
        
        if filters.location_city:
            query["location.city"] = filters.location_city
        
        # ë²”ìœ„ ì¿¼ë¦¬ (ë³µí•© ì¸ë±ìŠ¤ ê³ ë ¤)
        if filters.min_employee_count is not None or filters.max_employee_count is not None:
            employee_query = {}
            if filters.min_employee_count is not None:
                employee_query["$gte"] = filters.min_employee_count
            if filters.max_employee_count is not None:
                employee_query["$lte"] = filters.max_employee_count
            query["employee_count"] = employee_query
        
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë³„ë„ ì¸ë±ìŠ¤ í™œìš©)
        if filters.search_query:
            query["$text"] = {"$search": filters.search_query}
        
        # ì •ë ¬ ìµœì í™”
        sort_options = {
            "created_at": [("created_at", -1)],
            "performance_score": [("performance_metrics.overall_score", -1)],
            "employee_count": [("employee_count", -1)],
            "business_name": [("business_name", 1)]
        }
        
        sort_spec = sort_options.get(filters.sort_by, [("created_at", -1)])
        if filters.sort_order == "asc":
            sort_spec = [(field, 1 if order == -1 else -1) for field, order in sort_spec]
        
        # ì§‘ê³„ íŒŒì´í”„ë¼ì¸ (countì™€ ë°ì´í„°ë¥¼ í•œ ë²ˆì—)
        pipeline = [
            {"$match": query},
            {
                "$facet": {
                    "data": [
                        {"$sort": dict(sort_spec)},
                        {"$skip": (params.page - 1) * params.size},
                        {"$limit": params.size}
                    ],
                    "count": [{"$count": "total"}]
                }
            }
        ]
        
        result = await self.collection.aggregate(pipeline).to_list(length=1)
        
        if not result:
            return Page(items=[], total=0, page=params.page, size=params.size)
        
        data = result[0]["data"]
        total = result[0]["count"][0]["total"] if result[0]["count"] else 0
        
        businesses = [Business(**doc) for doc in data]
        
        return Page(items=businesses, total=total, page=params.page, size=params.size)
```

### ìºì‹± ì „ëµ
```python
# app/domains/businesses/services/cache_service.py

from typing import Optional, Any, List
import json
import hashlib
from datetime import datetime, timedelta

class BusinessCacheService:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.default_ttl = 1800  # 30ë¶„
    
    async def get_business_analysis(self, business_id: str) -> Optional[Dict[str, Any]]:
        """ë¶„ì„ ê²°ê³¼ ìºì‹œ ì¡°íšŒ"""
        cache_key = f"business:analysis:{business_id}"
        cached_data = await self.redis.get(cache_key)
        
        if cached_data:
            data = json.loads(cached_data)
            # ìºì‹œ ìœ íš¨ì„± ê²€ì¦
            if self._is_cache_valid(data):
                return data
            else:
                await self.redis.delete(cache_key)
        
        return None
    
    async def set_business_analysis(
        self, business_id: str, analysis_data: Dict[str, Any], ttl: int = None
    ):
        """ë¶„ì„ ê²°ê³¼ ìºì‹±"""
        cache_key = f"business:analysis:{business_id}"
        
        # ìºì‹œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        cache_data = {
            "data": analysis_data,
            "cached_at": datetime.utcnow().isoformat(),
            "ttl": ttl or self.default_ttl
        }
        
        await self.redis.setex(
            cache_key, 
            ttl or self.default_ttl, 
            json.dumps(cache_data, default=str)
        )
    
    async def get_filtered_businesses(
        self, filters_hash: str, page: int, size: int
    ) -> Optional[List[Dict[str, Any]]]:
        """í•„í„°ë§ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ë¡ ìºì‹œ"""
        cache_key = f"businesses:filtered:{filters_hash}:{page}:{size}"
        cached_data = await self.redis.get(cache_key)
        
        if cached_data:
            return json.loads(cached_data)
        
        return None
    
    async def set_filtered_businesses(
        self, filters_hash: str, page: int, size: int, businesses: List[Dict[str, Any]]
    ):
        """í•„í„°ë§ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ë¡ ìºì‹± (5ë¶„)"""
        cache_key = f"businesses:filtered:{filters_hash}:{page}:{size}"
        await self.redis.setex(cache_key, 300, json.dumps(businesses, default=str))
    
    async def invalidate_business_cache(self, business_id: str):
        """íŠ¹ì • ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”"""
        patterns = [
            f"business:analysis:{business_id}",
            f"business:recommendations:*:{business_id}",
            f"businesses:filtered:*"  # ëª©ë¡ ìºì‹œë„ ë¬´íš¨í™”
        ]
        
        for pattern in patterns:
            if "*" in pattern:
                keys = await self.redis.keys(pattern)
                if keys:
                    await self.redis.delete(*keys)
            else:
                await self.redis.delete(pattern)
    
    def _is_cache_valid(self, cached_data: Dict[str, Any]) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì¦"""
        try:
            cached_at = datetime.fromisoformat(cached_data["cached_at"])
            ttl = cached_data.get("ttl", self.default_ttl)
            
            return datetime.utcnow() < cached_at + timedelta(seconds=ttl)
        except (KeyError, ValueError):
            return False
    
    async def warm_up_cache(self):
        """ìºì‹œ ì›Œë°ì—… (ì¸ê¸° ìˆëŠ” ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ)"""
        # ì¸ê¸° ìˆëŠ” í•„í„° ì¡°í•© ë¯¸ë¦¬ ìºì‹±
        popular_filters = [
            {"industry": "AI", "business_size": "startup"},
            {"industry": "ë°”ì´ì˜¤", "business_size": "sme"},
            {"location_city": "ì„œìš¸", "business_size": "startup"}
        ]
        
        for filters in popular_filters:
            # TODO: ì‹¤ì œ ë°ì´í„°ë¡œ ìºì‹œ ì±„ìš°ê¸°
            pass
```

## ğŸ§ª í…ŒìŠ¤íŒ…

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
# tests/domains/businesses/test_business_service.py

import pytest
from unittest.mock import AsyncMock, MagicMock
from app.domains.businesses.services.business_service import BusinessService
from app.domains.businesses.models.business import Business, BusinessAnalysis

class TestBusinessService:
    @pytest.fixture
    def mock_repository(self):
        return AsyncMock()
    
    @pytest.fixture
    def mock_announcement_service(self):
        return AsyncMock()
    
    @pytest.fixture
    def mock_cache_service(self):
        return AsyncMock()
    
    @pytest.fixture
    def mock_ml_service(self):
        return AsyncMock()
    
    @pytest.fixture
    def business_service(
        self, mock_repository, mock_announcement_service, 
        mock_cache_service, mock_ml_service
    ):
        return BusinessService(
            repository=mock_repository,
            announcement_service=mock_announcement_service,
            cache_service=mock_cache_service,
            ml_service=mock_ml_service
        )
    
    @pytest.fixture
    def sample_business(self):
        return Business(
            id="64f8a1b2c3d4e5f6a7b8c9d0",
            business_name="í…ŒìŠ¤íŠ¸ AI ìŠ¤íƒ€íŠ¸ì—…",
            business_type="ê¸°ìˆ ê¸°ì—…",
            industry="AI",
            business_size="startup",
            employee_count=25,
            business_categories=["AI", "ì†Œí”„íŠ¸ì›¨ì–´"],
            technology_stack=["Python", "TensorFlow"]
        )
    
    @pytest.mark.asyncio
    async def test_get_comprehensive_analysis(
        self, business_service, mock_repository, mock_ml_service, sample_business
    ):
        """ì¢…í•© ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # Given
        business_id = sample_business.id
        mock_repository.get_by_id.return_value = sample_business
        
        mock_ml_service.analyze_business_comprehensive.return_value = MagicMock(
            performance_score=0.85,
            success_probability=0.78,
            announcement_compatibility=0.92,
            strengths=["AI ì „ë¬¸ì„±", "ë¹ ë¥¸ ê°œë°œ"],
            weaknesses=["ë§ˆì¼€íŒ…", "ìê¸ˆ ì¡°ë‹¬"],
            recommended_opportunities=["AI-001", "AI-002"],
            confidence=0.89
        )
        
        # When
        result = await business_service.get_comprehensive_analysis(business_id)
        
        # Then
        assert result is not None
        assert result.business_id == business_id
        assert result.performance_score == 0.85
        assert result.success_probability == 0.78
        assert len(result.competitive_advantages) == 2
        assert len(result.improvement_areas) == 2
        assert result.confidence_score == 0.89
        
        # ìºì‹œ ì„¤ì • í™•ì¸
        business_service.cache.set.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_compare_businesses(
        self, business_service, mock_repository, mock_ml_service
    ):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë¹„êµ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # Given
        business_ids = ["id1", "id2", "id3"]
        mock_businesses = [
            Business(id="id1", business_name="Business 1", industry="AI"),
            Business(id="id2", business_name="Business 2", industry="AI"),
            Business(id="id3", business_name="Business 3", industry="BIO")
        ]
        
        mock_repository.get_multiple_by_ids.return_value = mock_businesses
        business_service.get_comprehensive_analysis = AsyncMock(
            return_value=BusinessAnalysis(
                business_id="test",
                analysis_type="comprehensive",
                performance_score=0.8
            )
        )
        
        mock_ml_service.generate_comparison_insights.return_value = {
            "winner": "id1",
            "recommendations": ["Focus on AI", "Improve marketing"]
        }
        
        # When
        result = await business_service.compare_businesses(
            business_ids, ["performance", "growth"], True
        )
        
        # Then
        assert "businesses" in result
        assert "matrix" in result
        assert "insights" in result
        assert len(result["businesses"]) == 3
    
    @pytest.mark.asyncio
    async def test_get_personalized_recommendations(
        self, business_service, mock_repository, mock_ml_service
    ):
        """ê°œì¸í™” ì¶”ì²œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        # Given
        user_id = "user123"
        mock_candidates = [
            Business(id="b1", business_name="Candidate 1"),
            Business(id="b2", business_name="Candidate 2")
        ]
        
        mock_repository.find_recommendation_candidates.return_value = mock_candidates
        
        mock_ml_service.score_business_recommendations.return_value = [
            MagicMock(id="b1", recommendation_score=0.9),
            MagicMock(id="b2", recommendation_score=0.7)
        ]
        
        business_service._analyze_user_preferences = AsyncMock(
            return_value=MagicMock(
                interests=["AI", "startup"],
                experience_level="intermediate",
                preferred_industries=["tech"]
            )
        )
        
        business_service._generate_recommendation_reasons = AsyncMock(
            return_value=["High growth potential", "Matching tech stack"]
        )
        
        # When
        result = await business_service.get_personalized_recommendations(
            user_id, None, 10
        )
        
        # Then
        assert len(result) <= 10
        assert result[0].recommendation_score >= result[1].recommendation_score
```

### í†µí•© í…ŒìŠ¤íŠ¸
```python
# tests/domains/businesses/test_business_integration.py

@pytest.mark.asyncio
async def test_business_full_workflow(test_client, test_db):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    
    # 1. ë¹„ì¦ˆë‹ˆìŠ¤ ìƒì„±
    business_data = {
        "business_name": "í†µí•©í…ŒìŠ¤íŠ¸ AI íšŒì‚¬",
        "business_type": "ê¸°ìˆ ê¸°ì—…",
        "industry": "AI",
        "business_size": "startup",
        "employee_count": 30,
        "business_categories": ["AI", "ML"],
        "technology_stack": ["Python", "PyTorch"]
    }
    
    response = await test_client.post("/api/v1/businesses/", json=business_data)
    assert response.status_code == 201
    business = response.json()
    business_id = business["id"]
    
    # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¡°íšŒ
    response = await test_client.get(f"/api/v1/businesses/{business_id}")
    assert response.status_code == 200
    retrieved_business = response.json()
    assert retrieved_business["business_name"] == business_data["business_name"]
    
    # 3. ë¶„ì„ ìš”ì²­
    response = await test_client.get(
        f"/api/v1/businesses/{business_id}/analysis",
        params={"analysis_type": "comprehensive"}
    )
    assert response.status_code == 200
    analysis = response.json()
    assert "performance_score" in analysis
    assert "related_announcements" in analysis
    
    # 4. ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ë¡ í•„í„°ë§
    response = await test_client.get(
        "/api/v1/businesses/",
        params={
            "industry": "AI",
            "business_size": "startup",
            "min_employee_count": 20
        }
    )
    assert response.status_code == 200
    businesses = response.json()
    assert businesses["total"] >= 1
    
    # 5. ë¹„êµ ë¶„ì„
    # ì¶”ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ìƒì„±
    business_data_2 = {**business_data, "business_name": "AI íšŒì‚¬ 2"}
    response = await test_client.post("/api/v1/businesses/", json=business_data_2)
    business_2_id = response.json()["id"]
    
    response = await test_client.post(
        "/api/v1/businesses/compare",
        json={
            "business_ids": [business_id, business_2_id],
            "comparison_criteria": ["performance", "growth"]
        }
    )
    assert response.status_code == 200
    comparison = response.json()
    assert "comparison_matrix" in comparison
    assert len(comparison["businesses"]) == 2
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­

### ì„±ëŠ¥ ë©”íŠ¸ë¦­
```python
# app/domains/businesses/monitoring/metrics.py

from prometheus_client import Counter, Histogram, Gauge
import time
from functools import wraps

# ë©”íŠ¸ë¦­ ì •ì˜
business_requests_total = Counter(
    'business_api_requests_total',
    'Total business API requests',
    ['method', 'endpoint', 'status']
)

business_request_duration = Histogram(
    'business_api_request_duration_seconds',
    'Business API request duration',
    ['method', 'endpoint']
)

business_analysis_duration = Histogram(
    'business_analysis_duration_seconds',
    'Business analysis processing time',
    ['analysis_type']
)

active_businesses_gauge = Gauge(
    'active_businesses_total',
    'Total number of active businesses'
)

recommendation_accuracy = Gauge(
    'business_recommendation_accuracy',
    'Business recommendation accuracy score'
)

def monitor_api_performance(endpoint_name: str):
    """API ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            status = "success"
            
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                raise
            finally:
                duration = time.time() - start_time
                
                business_requests_total.labels(
                    method="GET",  # ì‹¤ì œë¡œëŠ” requestì—ì„œ ì¶”ì¶œ
                    endpoint=endpoint_name,
                    status=status
                ).inc()
                
                business_request_duration.labels(
                    method="GET",
                    endpoint=endpoint_name
                ).observe(duration)
        
        return wrapper
    return decorator

async def update_business_metrics():
    """ì •ê¸°ì ì¸ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
    # í™œì„± ë¹„ì¦ˆë‹ˆìŠ¤ ìˆ˜ ì—…ë°ì´íŠ¸
    from ..repositories.business_repository import BusinessRepository
    repo = BusinessRepository()
    
    active_count = await repo.count_active_businesses()
    active_businesses_gauge.set(active_count)
    
    # ì¶”ì²œ ì •í™•ë„ ì—…ë°ì´íŠ¸
    accuracy = await calculate_recommendation_accuracy()
    recommendation_accuracy.set(accuracy)
```

## ğŸ”„ ì—…ë°ì´íŠ¸ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ì‚¬í•­ | ì‘ì„±ì |
|------|------|----------|--------|
| 1.0.0 | 2025-08-14 | ì´ˆê¸° Business ë„ë©”ì¸ êµ¬í˜„ ë¬¸ì„œ ì‘ì„± | Backend Team |

---

*Business ë„ë©”ì¸ì€ Korea Public Data í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ë„ë©”ì¸ìœ¼ë¡œ, ì§€ì†ì ì¸ ê°œì„ ê³¼ í™•ì¥ì„ í†µí•´ ë” ë‚˜ì€ ì‚¬ì—… ë¶„ì„ ë° ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.*