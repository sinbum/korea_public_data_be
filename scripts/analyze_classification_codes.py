#!/usr/bin/env python3
"""
K-Startup API ë¶„ë¥˜ ì½”ë“œ ì‹¤ì œ ì‚¬ìš© í˜„í™© ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì‹¤ì œ API ì‘ë‹µì—ì„œ ë°œê²¬ëœ ë¶„ë¥˜ ì½”ë“œì™€ í˜„ì¬ ì •ì˜ëœ enum í´ë˜ìŠ¤ë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import json
import os
from pathlib import Path
from typing import Dict, Any, List, Set, Optional
import logging
from collections import Counter
import sys

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
sys_path = os.path.abspath('.')
if sys_path not in sys.path:
    sys.path.insert(0, sys_path)

# ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
RESULTS_DIR = Path("tests/live/results")
ANALYSIS_OUTPUT_DIR = Path("docs/reports/classification_analysis")
ANALYSIS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


class ClassificationCodeAnalyzer:
    """ë¶„ë¥˜ ì½”ë“œ ì‹¤ì œ ì‚¬ìš© í˜„í™© ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.sample_files = {
            "announcements": "announcements_basic_sample.json",
            "business": "business_basic_sample.json", 
            "content": "content_basic_sample.json",
            "statistics": "statistics_basic_sample.json"
        }
        self.analysis_results = {}
        
        # í˜„ì¬ ì •ì˜ëœ ë¶„ë¥˜ ì½”ë“œë“¤ (enum ê¸°ë°˜)
        self.defined_business_categories = {
            "cmrczn_tab1": "ì‚¬ì—…í™”",
            "cmrczn_tab2": "ì°½ì—…êµìœ¡", 
            "cmrczn_tab3": "ì‹œì„¤,ê³µê°„,ë³´ìœ¡",
            "cmrczn_tab4": "ë©˜í† ë§,ì»¨ì„¤íŒ…",
            "cmrczn_tab5": "í–‰ì‚¬,ë„¤íŠ¸ì›Œí¬",
            "cmrczn_tab6": "ê¸°ìˆ ê°œë°œ R&D",
            "cmrczn_tab7": "ìœµì",
            "cmrczn_tab8": "ì¸ë ¥",
            "cmrczn_tab9": "ê¸€ë¡œë²Œ"
        }
        
        self.defined_content_categories = {
            "notice_matr": "ì •ì±… ë° ê·œì œì •ë³´(ê³µì§€ì‚¬í•­)",
            "fnd_scs_case": "ì°½ì—…ìš°ìˆ˜ì‚¬ë¡€", 
            "kstartup_isse_trd": "ìƒíƒœê³„ ì´ìŠˆ, ë™í–¥"
        }
    
    def analyze_all_classifications(self):
        """ëª¨ë“  ë¶„ë¥˜ ì½”ë“œ ë¶„ì„"""
        logger.info("Starting classification code analysis...")
        
        for endpoint_name, file_name in self.sample_files.items():
            sample_path = RESULTS_DIR / file_name
            
            if sample_path.exists():
                logger.info(f"Analyzing {endpoint_name} classification codes...")
                analysis = self.analyze_endpoint_classifications(endpoint_name, sample_path)
                self.analysis_results[endpoint_name] = analysis
            else:
                logger.warning(f"Sample file not found: {sample_path}")
        
        # ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.save_analysis_results()
        
        logger.info("Classification code analysis completed")
    
    def analyze_endpoint_classifications(self, endpoint_name: str, sample_path: Path) -> Dict[str, Any]:
        """ê°œë³„ ì—”ë“œí¬ì¸íŠ¸ ë¶„ë¥˜ ì½”ë“œ ë¶„ì„"""
        
        # ì‹¤ì œ ì‘ë‹µ ë°ì´í„° ë¡œë“œ
        with open(sample_path, 'r', encoding='utf-8') as f:
            response_data = json.load(f)
        
        analysis = {
            "endpoint": endpoint_name,
            "total_items": len(response_data.get("data", [])),
            "classification_fields": [],
            "actual_codes": {},
            "code_distribution": {},
            "mapping_analysis": {}
        }
        
        if endpoint_name == "announcements":
            analysis = self.analyze_announcement_classifications(response_data, analysis)
        elif endpoint_name == "content":
            analysis = self.analyze_content_classifications(response_data, analysis)
        elif endpoint_name == "business":
            analysis = self.analyze_business_classifications(response_data, analysis)
        elif endpoint_name == "statistics":
            analysis = self.analyze_statistics_classifications(response_data, analysis)
        
        return analysis
    
    def analyze_announcement_classifications(self, response_data: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ê³µê³  ì •ë³´ ë¶„ë¥˜ ì½”ë“œ ë¶„ì„"""
        
        data_items = response_data.get("data", [])
        analysis["classification_fields"] = ["business_category", "support_region", "supervising_institution"]
        
        # business_category ë¶„ì„
        business_categories = []
        support_regions = []
        supervising_institutions = []
        
        for item in data_items:
            if item.get("business_category"):
                business_categories.append(item["business_category"])
            if item.get("support_region"):
                support_regions.append(item["support_region"])
            if item.get("supervising_institution"):
                supervising_institutions.append(item["supervising_institution"])
        
        analysis["actual_codes"] = {
            "business_category": list(set(business_categories)),
            "support_region": list(set(support_regions)),
            "supervising_institution": list(set(supervising_institutions))
        }
        
        analysis["code_distribution"] = {
            "business_category": dict(Counter(business_categories)),
            "support_region": dict(Counter(support_regions)),
            "supervising_institution": dict(Counter(supervising_institutions))
        }
        
        # ì •ì˜ëœ ì½”ë“œì™€ ì‹¤ì œ ì‚¬ìš© ì½”ë“œ ë§¤í•‘ ë¶„ì„
        analysis["mapping_analysis"]["business_category"] = self.analyze_business_category_mapping(business_categories)
        
        return analysis
    
    def analyze_content_classifications(self, response_data: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ì½˜í…ì¸  ì •ë³´ ë¶„ë¥˜ ì½”ë“œ ë¶„ì„"""
        
        data_items = response_data.get("data", [])
        analysis["classification_fields"] = ["content_type"]
        
        # content_type ë¶„ì„
        content_types = []
        
        for item in data_items:
            if item.get("content_type"):
                content_types.append(item["content_type"])
        
        analysis["actual_codes"] = {
            "content_type": list(set(content_types))
        }
        
        analysis["code_distribution"] = {
            "content_type": dict(Counter(content_types))
        }
        
        # ì •ì˜ëœ ì½”ë“œì™€ ì‹¤ì œ ì‚¬ìš© ì½”ë“œ ë§¤í•‘ ë¶„ì„
        analysis["mapping_analysis"]["content_type"] = self.analyze_content_category_mapping(content_types)
        
        return analysis
    
    def analyze_business_classifications(self, response_data: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ì—… ì •ë³´ ë¶„ë¥˜ ì½”ë“œ ë¶„ì„"""
        
        data_items = response_data.get("data", [])
        analysis["classification_fields"] = ["business_category"]
        
        # business_category ë¶„ì„
        business_categories = []
        
        for item in data_items:
            if item.get("business_category"):
                business_categories.append(item["business_category"])
        
        analysis["actual_codes"] = {
            "business_category": list(set(business_categories))
        }
        
        analysis["code_distribution"] = {
            "business_category": dict(Counter(business_categories))
        }
        
        # ì •ì˜ëœ ì½”ë“œì™€ ì‹¤ì œ ì‚¬ìš© ì½”ë“œ ë§¤í•‘ ë¶„ì„
        analysis["mapping_analysis"]["business_category"] = self.analyze_business_category_mapping(business_categories)
        
        return analysis
    
    def analyze_statistics_classifications(self, response_data: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë¶„ë¥˜ ì½”ë“œ ë¶„ì„ (ë¶„ë¥˜ í•„ë“œ ì—†ìŒ)"""
        
        data_items = response_data.get("data", [])
        analysis["classification_fields"] = []
        analysis["actual_codes"] = {}
        analysis["code_distribution"] = {}
        analysis["mapping_analysis"] = {"note": "í†µê³„ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸ì—ëŠ” ë¶„ë¥˜ í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        return analysis
    
    def analyze_business_category_mapping(self, actual_categories: List[str]) -> Dict[str, Any]:
        """ì‚¬ì—… ë¶„ë¥˜ ì½”ë“œ ë§¤í•‘ ë¶„ì„"""
        
        # ì‹¤ì œ ì‚¬ìš©ëœ í•œê¸€ ì¹´í…Œê³ ë¦¬ë“¤
        unique_categories = list(set(actual_categories))
        
        mapping_results = {
            "actual_korean_categories": unique_categories,
            "defined_enum_codes": list(self.defined_business_categories.keys()),
            "defined_enum_descriptions": list(self.defined_business_categories.values()),
            "mapping_gaps": {},
            "mapping_status": "ë¯¸ë§¤í•‘" # APIëŠ” í•œê¸€ê°’ ì‚¬ìš©, enumì€ ì˜ë¬¸ì½”ë“œ ì‚¬ìš©
        }
        
        # ì‹¤ì œ í•œê¸€ ì¹´í…Œê³ ë¦¬ì™€ ì •ì˜ëœ enum ì„¤ëª… ê°„ ë§¤ì¹­ ë¶„ì„
        actual_set = set(unique_categories)
        defined_set = set(self.defined_business_categories.values())
        
        mapping_results["mapping_gaps"] = {
            "actual_not_in_defined": list(actual_set - defined_set),
            "defined_not_in_actual": list(defined_set - actual_set),
            "matched_categories": list(actual_set & defined_set)
        }
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤í•‘ ì¶”ì²œ
        mapping_results["recommended_mappings"] = self.suggest_category_mappings(unique_categories)
        
        return mapping_results
    
    def analyze_content_category_mapping(self, actual_categories: List[str]) -> Dict[str, Any]:
        """ì½˜í…ì¸  ë¶„ë¥˜ ì½”ë“œ ë§¤í•‘ ë¶„ì„"""
        
        # ì‹¤ì œ ì‚¬ìš©ëœ ì˜ë¬¸ ì½”ë“œë“¤
        unique_categories = list(set(actual_categories))
        
        mapping_results = {
            "actual_code_categories": unique_categories,
            "defined_enum_codes": list(self.defined_content_categories.keys()),
            "defined_enum_descriptions": list(self.defined_content_categories.values()),
            "mapping_status": "ì™„ì „ë§¤í•‘" # APIì™€ enum ëª¨ë‘ ì˜ë¬¸ì½”ë“œ ì‚¬ìš©
        }
        
        # ì‹¤ì œ ì½”ë“œì™€ ì •ì˜ëœ enum ì½”ë“œ ê°„ ë§¤ì¹­ ë¶„ì„
        actual_set = set(unique_categories)
        defined_set = set(self.defined_content_categories.keys())
        
        mapping_results["mapping_coverage"] = {
            "actual_codes_covered": list(actual_set & defined_set),
            "actual_codes_missing": list(actual_set - defined_set),
            "defined_codes_unused": list(defined_set - actual_set),
            "coverage_percentage": (len(actual_set & defined_set) / len(actual_set) * 100) if actual_set else 0
        }
        
        return mapping_results
    
    def suggest_category_mappings(self, actual_categories: List[str]) -> Dict[str, str]:
        """ì‹¤ì œ ì¹´í…Œê³ ë¦¬ì™€ ì •ì˜ëœ enum ê°„ ë§¤í•‘ ì¶”ì²œ"""
        
        suggestions = {}
        
        # ìˆ˜ë™ ë§¤í•‘ (ìœ ì‚¬ë„ ê¸°ë°˜)
        mapping_suggestions = {
            "ê¸°ìˆ ê°œë°œ(R&amp;D)": "cmrczn_tab6",  # ê¸°ìˆ ê°œë°œ R&D
            "ê¸°ìˆ ê°œë°œ(R&D)": "cmrczn_tab6",    # ê¸°ìˆ ê°œë°œ R&D
            "ë©˜í† ë§ã†ì»¨ì„¤íŒ…ã†êµìœ¡": "cmrczn_tab4", # ë©˜í† ë§,ì»¨ì„¤íŒ… 
            "ì°½ì—…êµìœ¡": "cmrczn_tab2",         # ì°½ì—…êµìœ¡
            "ì‚¬ì—…í™”": "cmrczn_tab1",           # ì‚¬ì—…í™”
            "ì‹œì„¤ã†ê³µê°„ã†ë³´ìœ¡": "cmrczn_tab3", # ì‹œì„¤,ê³µê°„,ë³´ìœ¡
            "í–‰ì‚¬ã†ë„¤íŠ¸ì›Œí¬": "cmrczn_tab5",   # í–‰ì‚¬,ë„¤íŠ¸ì›Œí¬
            "ìœµì": "cmrczn_tab7",             # ìœµì
            "ì¸ë ¥": "cmrczn_tab8",             # ì¸ë ¥
            "ê¸€ë¡œë²Œ": "cmrczn_tab9",           # ê¸€ë¡œë²Œ
            "íŒë¡œã†í•´ì™¸ì§„ì¶œ": "cmrczn_tab9"   # ê¸€ë¡œë²Œ (ì¶”ê°€ ë§¤í•‘)
        }
        
        for actual_category in actual_categories:
            # HTML ì—”í‹°í‹° ì •ë¦¬
            clean_category = actual_category.replace("&amp;", "&")
            
            if clean_category in mapping_suggestions:
                enum_code = mapping_suggestions[clean_category]
                enum_description = self.defined_business_categories.get(enum_code, "")
                suggestions[actual_category] = {
                    "suggested_enum_code": enum_code,
                    "enum_description": enum_description,
                    "confidence": "high"
                }
            else:
                suggestions[actual_category] = {
                    "suggested_enum_code": None,
                    "enum_description": "ë§¤í•‘ ë¶ˆê°€",
                    "confidence": "none"
                }
        
        return suggestions
    
    def save_analysis_results(self):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        
        # JSON í˜•íƒœë¡œ ìƒì„¸ ê²°ê³¼ ì €ì¥
        results_file = ANALYSIS_OUTPUT_DIR / "classification_code_analysis_detailed.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2, default=str)
        
        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_analysis_report()
        
        logger.info(f"Analysis results saved to {ANALYSIS_OUTPUT_DIR}")
    
    def generate_analysis_report(self):
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        report_lines = [
            "# K-Startup API ë¶„ë¥˜ ì½”ë“œ ì‹¤ì œ ì‚¬ìš© í˜„í™© ë¶„ì„ ë¦¬í¬íŠ¸",
            "",
            f"ë¶„ì„ ì¼ì‹œ: {self._get_current_timestamp()}",
            "",
            "## ğŸ“‹ ë¶„ì„ ê°œìš”",
            "",
            f"- ë¶„ì„ëœ ì—”ë“œí¬ì¸íŠ¸: {len(self.analysis_results)}ê°œ",
            "- ë¶„ì„ ë²”ìœ„: ì‹¤ì œ API ì‘ë‹µ ë°ì´í„°ì˜ ë¶„ë¥˜ ì½”ë“œ vs ì •ì˜ëœ enum í´ë˜ìŠ¤",
            "- ëª©ì : ë¶„ë¥˜ ì½”ë“œ ì •ì˜ì™€ ì‹¤ì œ ì‚¬ìš© í˜„í™© ê°„ì˜ ì°¨ì´ì  ë° ê°œì„  ë°©ì•ˆ ë„ì¶œ",
            "",
        ]
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ ìƒì„¸ ë¶„ì„
        for endpoint, analysis in self.analysis_results.items():
            report_lines.extend([
                f"## ğŸ” {endpoint.title()} ì—”ë“œí¬ì¸íŠ¸ ë¶„ì„",
                ""
            ])
            
            # ê¸°ë³¸ ì •ë³´
            report_lines.extend([
                "### ğŸ“Š ê¸°ë³¸ ì •ë³´",
                "",
                f"- ë¶„ì„ëœ ë°ì´í„° ìˆ˜: {analysis['total_items']}ê°œ",
                f"- ë¶„ë¥˜ í•„ë“œ: {', '.join(analysis['classification_fields']) if analysis['classification_fields'] else 'ì—†ìŒ'}",
                ""
            ])
            
            # ì‹¤ì œ ì‚¬ìš©ëœ ë¶„ë¥˜ ì½”ë“œ
            if analysis["actual_codes"]:
                report_lines.extend([
                    "### ğŸ·ï¸ ì‹¤ì œ ì‚¬ìš©ëœ ë¶„ë¥˜ ì½”ë“œ",
                    ""
                ])
                
                for field_name, codes in analysis["actual_codes"].items():
                    report_lines.append(f"#### {field_name}")
                    for code in codes:
                        count = analysis["code_distribution"][field_name].get(code, 0)
                        report_lines.append(f"- `{code}` ({count}íšŒ ì‚¬ìš©)")
                    report_lines.append("")
            
            # ë§¤í•‘ ë¶„ì„
            if analysis["mapping_analysis"]:
                report_lines.extend([
                    "### ğŸ”— ë§¤í•‘ ë¶„ì„",
                    ""
                ])
                
                for field_name, mapping_info in analysis["mapping_analysis"].items():
                    if field_name == "note":
                        report_lines.append(f"- {mapping_info}")
                        continue
                        
                    report_lines.append(f"#### {field_name}")
                    
                    if "mapping_status" in mapping_info:
                        status = mapping_info["mapping_status"]
                        status_icon = "âœ…" if status == "ì™„ì „ë§¤í•‘" else "âš ï¸" if status == "ë¶€ë¶„ë§¤í•‘" else "âŒ"
                        report_lines.append(f"- ë§¤í•‘ ìƒíƒœ: {status_icon} {status}")
                    
                    # ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ (ì˜ë¬¸ ì½”ë“œ) ë¶„ì„
                    if "mapping_coverage" in mapping_info:
                        coverage = mapping_info["mapping_coverage"]
                        report_lines.extend([
                            f"- ì»¤ë²„ë¦¬ì§€: {coverage['coverage_percentage']:.1f}%",
                            f"- ë§¤í•‘ëœ ì½”ë“œ: {', '.join(coverage['actual_codes_covered'])}",
                        ])
                        
                        if coverage["actual_codes_missing"]:
                            report_lines.append(f"- ëˆ„ë½ëœ ì½”ë“œ: {', '.join(coverage['actual_codes_missing'])}")
                        if coverage["defined_codes_unused"]:
                            report_lines.append(f"- ë¯¸ì‚¬ìš© ì •ì˜ ì½”ë“œ: {', '.join(coverage['defined_codes_unused'])}")
                    
                    # ì‚¬ì—… ì¹´í…Œê³ ë¦¬ (í•œê¸€ vs ì˜ë¬¸ ì½”ë“œ) ë¶„ì„
                    if "mapping_gaps" in mapping_info:
                        gaps = mapping_info["mapping_gaps"]
                        report_lines.extend([
                            "- ì‹¤ì œ ì‚¬ìš© (í•œê¸€): " + ", ".join(f"`{cat}`" for cat in mapping_info["actual_korean_categories"]),
                            "- ì •ì˜ëœ enum (ì˜ë¬¸): " + ", ".join(f"`{code}`" for code in mapping_info["defined_enum_codes"]),
                        ])
                        
                        if gaps["matched_categories"]:
                            report_lines.append(f"- ì¼ì¹˜í•˜ëŠ” ì„¤ëª…: {', '.join(gaps['matched_categories'])}")
                        if gaps["actual_not_in_defined"]:
                            report_lines.append(f"- ì •ì˜ë˜ì§€ ì•Šì€ ì‹¤ì œ ì¹´í…Œê³ ë¦¬: {', '.join(gaps['actual_not_in_defined'])}")
                    
                    # ë§¤í•‘ ì¶”ì²œ
                    if "recommended_mappings" in mapping_info:
                        report_lines.extend([
                            "",
                            "#### ğŸ“ ë§¤í•‘ ì¶”ì²œ",
                            "",
                            "| ì‹¤ì œ ì‚¬ìš© ì¹´í…Œê³ ë¦¬ | ì¶”ì²œ enum ì½”ë“œ | enum ì„¤ëª… | ì‹ ë¢°ë„ |",
                            "|-------------------|---------------|-----------|---------|"
                        ])
                        
                        for actual_cat, suggestion in mapping_info["recommended_mappings"].items():
                            enum_code = suggestion["suggested_enum_code"] or "ë¯¸ì •ì˜"
                            enum_desc = suggestion["enum_description"] or "-"
                            confidence = suggestion["confidence"]
                            confidence_icon = "ğŸŸ¢" if confidence == "high" else "ğŸŸ¡" if confidence == "medium" else "ğŸ”´"
                            
                            report_lines.append(f"| `{actual_cat}` | `{enum_code}` | {enum_desc} | {confidence_icon} {confidence} |")
                    
                    report_lines.append("")
        
        # ì¢…í•© ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­
        report_lines.extend([
            "## ğŸ’¡ ì¢…í•© ë¶„ì„ ê²°ê³¼",
            "",
            "### âœ… ë°œê²¬ ì‚¬í•­",
            "",
            "1. **ì½˜í…ì¸  ë¶„ë¥˜ ì½”ë“œ**: âœ… ì™„ì „ ë§¤í•‘",
            "   - API ì‘ë‹µê³¼ enum ì •ì˜ê°€ ì™„ì „íˆ ì¼ì¹˜ (ì˜ë¬¸ ì½”ë“œ ì‚¬ìš©)",
            "   - `fnd_scs_case`, `notice_matr` ì½”ë“œê°€ ì‹¤ì œë¡œ ì‚¬ìš©ë¨",
            "",
            "2. **ì‚¬ì—… ë¶„ë¥˜ ì½”ë“œ**: âš ï¸ ë¶ˆì¼ì¹˜ - ë§¤í•‘ í•„ìš”", 
            "   - API ì‘ë‹µ: í•œê¸€ ì¹´í…Œê³ ë¦¬ ì‚¬ìš© (`ê¸°ìˆ ê°œë°œ(R&D)`, `ë©˜í† ë§ã†ì»¨ì„¤íŒ…ã†êµìœ¡` ë“±)",
            "   - enum ì •ì˜: ì˜ë¬¸ ì½”ë“œ ì‚¬ìš© (`cmrczn_tab1` ~ `cmrczn_tab9`)",
            "   - ì˜ë¯¸ì ìœ¼ë¡œëŠ” ì¼ì¹˜í•˜ì§€ë§Œ í˜•íƒœê°€ ë‹¤ë¦„",
            "",
            "### ğŸ”§ ê¶Œì¥ ê°œì„ ì‚¬í•­",
            "",
            "#### ì¦‰ì‹œ ê°œì„  í•„ìš”",
            "1. **ì‚¬ì—… ë¶„ë¥˜ ì½”ë“œ enum ìˆ˜ì •**:",
            "   - í˜„ì¬: ì˜ë¬¸ ì½”ë“œ ì •ì˜ (`cmrczn_tab1` ë“±)",
            "   - ë³€ê²½: ì‹¤ì œ API í•œê¸€ ì‘ë‹µ ê¸°ë°˜ enum ìƒì„±",
            "   - ì˜ˆì‹œ: `BusinessCategoryKorean` enum í´ë˜ìŠ¤ ì¶”ê°€",
            "",
            "2. **ì—­ë°©í–¥ ë§¤í•‘ í•¨ìˆ˜ êµ¬í˜„**:",
            "   - í•œê¸€ ì¹´í…Œê³ ë¦¬ â†’ ì˜ë¬¸ ì½”ë“œ ë³€í™˜",
            "   - ì˜ë¬¸ ì½”ë“œ â†’ í•œê¸€ ì„¤ëª… ë³€í™˜",
            "",
            "#### ì¤‘ì¥ê¸° ê°œì„ ì‚¬í•­",
            "1. **ë¶„ë¥˜ ì½”ë“œ í†µí•© ê´€ë¦¬**:",
            "   - API ì‘ë‹µ í˜•íƒœì™€ ë‚´ë¶€ ì²˜ë¦¬ í˜•íƒœ ë¶„ë¦¬",
            "   - ë‹¤êµ­ì–´ ì§€ì› ê³ ë ¤í•œ ë¶„ë¥˜ ì²´ê³„",
            "",
            "2. **ë™ì  ë¶„ë¥˜ ì½”ë“œ ê°ì§€**:",
            "   - ì‹ ê·œ ë¶„ë¥˜ ì½”ë“œ ìë™ ê°ì§€",
            "   - enum ì •ì˜ì™€ ì‹¤ì œ ì‚¬ìš© ì°¨ì´ ëª¨ë‹ˆí„°ë§",
            "",
            "## ğŸ“Š êµ¬ì²´ì  ë§¤í•‘ í˜„í™©",
            "",
            "### ì‚¬ì—… ì¹´í…Œê³ ë¦¬ ë§¤í•‘ í…Œì´ë¸”",
            "",
            "| ì‹¤ì œ API ì‘ë‹µ (í•œê¸€) | í˜„ì¬ enum ì½”ë“œ | í˜„ì¬ enum ì„¤ëª… | ìƒíƒœ |",
            "|---------------------|---------------|---------------|------|",
            "| `ê¸°ìˆ ê°œë°œ(R&D)` | `cmrczn_tab6` | ê¸°ìˆ ê°œë°œ R&D | âœ… ë§¤í•‘ ê°€ëŠ¥ |",
            "| `ë©˜í† ë§ã†ì»¨ì„¤íŒ…ã†êµìœ¡` | `cmrczn_tab4` | ë©˜í† ë§,ì»¨ì„¤íŒ… | âš ï¸ ë¶€ë¶„ ì¼ì¹˜ |",
            "| `ì°½ì—…êµìœ¡` | `cmrczn_tab2` | ì°½ì—…êµìœ¡ | âœ… ì™„ì „ ì¼ì¹˜ |",
            "",
            "### ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬ ë§¤í•‘ í…Œì´ë¸”",
            "",
            "| ì‹¤ì œ API ì‘ë‹µ | í˜„ì¬ enum ì½”ë“œ | í˜„ì¬ enum ì„¤ëª… | ìƒíƒœ |",
            "|--------------|---------------|---------------|------|",
            "| `fnd_scs_case` | `fnd_scs_case` | ì°½ì—…ìš°ìˆ˜ì‚¬ë¡€ | âœ… ì™„ì „ ì¼ì¹˜ |",
            "| `notice_matr` | `notice_matr` | ì •ì±… ë° ê·œì œì •ë³´(ê³µì§€ì‚¬í•­) | âœ… ì™„ì „ ì¼ì¹˜ |",
            "",
            "---",
            "",
            "**ê²°ë¡ **: ì½˜í…ì¸  ë¶„ë¥˜ëŠ” ì™„ë²½í•˜ê²Œ ì •ì˜ë˜ì–´ ìˆìœ¼ë‚˜, ì‚¬ì—… ë¶„ë¥˜ ì½”ë“œëŠ” API ì‘ë‹µ í˜•íƒœì— ë§ëŠ” enum ì¬ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        ])
        
        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
        report_file = ANALYSIS_OUTPUT_DIR / "classification_code_analysis_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
    
    def _get_current_timestamp(self) -> str:
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” K-Startup API ë¶„ë¥˜ ì½”ë“œ ì‹¤ì œ ì‚¬ìš© í˜„í™© ë¶„ì„ ì‹œì‘...")
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ë³€ê²½
    os.chdir(Path(__file__).parent.parent)
    
    analyzer = ClassificationCodeAnalyzer()
    analyzer.analyze_all_classifications()
    
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“„ ë¦¬í¬íŠ¸ ìœ„ì¹˜: {ANALYSIS_OUTPUT_DIR}")
    print(f"   - ìƒì„¸ ê²°ê³¼: classification_code_analysis_detailed.json")
    print(f"   - ë¶„ì„ ë¦¬í¬íŠ¸: classification_code_analysis_report.md")


if __name__ == "__main__":
    main()